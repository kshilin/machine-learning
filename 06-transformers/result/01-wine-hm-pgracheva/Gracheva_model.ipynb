{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Внимание!!! Важно, что бы файлы с данными и исполняемый файл находились в одной папке, \n",
    "# тогда пути к тестовым и тренировочным наборам будут содержать только имена файлов.\n",
    "# \n",
    "# В пути к тренировочным и тестовым данным запрежается использовать абсалютную адресацию, \n",
    "# то есть адресацию, в которой присутствуют имена папок. Путь должен содержать только имя файла.\n",
    "#\n",
    "# Напоминание: под моделью машинного обучения понимаются все действия с исходными данными, \n",
    "# которые необходимо произвести, что бы сопоставить признаки целевому значению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 1 (библиотеки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный блок в области 1 выполняется преподавателем\n",
    "# \n",
    "# данный блок предназначен только для подключения необходимых библиотек\n",
    "# запрещается подключать библиотеки в других блоках\n",
    "# запрещается скрывать предупреждения системы\n",
    "# установка дополнительных библиотек размещается прямо здесь (обязательно закоментированы)\n",
    "# pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import RobustScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.model_selection import validation_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 2 (выполнение лучшей модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный блок(и) в области 2 выполняется преподавателем\n",
    "#\n",
    "# В области находится одна, единственная, итоговая модель машинного обучения с однозначными, \n",
    "# зафиксированными параметрами\n",
    "#\n",
    "# В данной области категорически запрещается искать, выбирать, улучшать, оптимизировать, \n",
    "# тюниговать и т.д. модель машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к тренировочному набору\n",
    "path_train = 'train.csv' # содержит только имя файла, без имен папок\n",
    "# Путь к тестовому набору\n",
    "path_test  = 'test.csv' # содержит только имя файла, без имен папок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок(и) обучения и поверки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.047</td>\n",
       "      <td>33.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>10.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.062</td>\n",
       "      <td>23.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.49</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.031</td>\n",
       "      <td>20.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.98956</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.33</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.030</td>\n",
       "      <td>43.5</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.49</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>15.7</td>\n",
       "      <td>0.054</td>\n",
       "      <td>36.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.99788</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.34</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.057</td>\n",
       "      <td>46.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.99751</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.045</td>\n",
       "      <td>61.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.99520</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.32</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.047</td>\n",
       "      <td>54.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.32</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.031</td>\n",
       "      <td>16.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.99437</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.38</td>\n",
       "      <td>11.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.054</td>\n",
       "      <td>47.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.99538</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0              7.0              0.15         0.38             2.2      0.047   \n",
       "1              7.2              0.26         0.32            10.4      0.062   \n",
       "2              6.2              0.36         0.38             3.2      0.031   \n",
       "3              8.6              0.36         0.26            11.1      0.030   \n",
       "4              7.4              0.27         0.52            15.7      0.054   \n",
       "..             ...               ...          ...             ...        ...   \n",
       "571            7.3              0.36         0.34            14.8      0.057   \n",
       "572            6.4              0.28         0.41             6.8      0.045   \n",
       "573            6.4              0.24         0.32            14.9      0.047   \n",
       "574            5.5              0.15         0.32            14.0      0.031   \n",
       "575            6.4              0.24         0.26             8.2      0.054   \n",
       "\n",
       "     free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                   33.0                  96.0  0.99280  3.13       0.39   \n",
       "1                   23.0                 114.0  0.99660  3.23       0.49   \n",
       "2                   20.0                  89.0  0.98956  3.06       0.33   \n",
       "3                   43.5                 171.0  0.99480  3.03       0.49   \n",
       "4                   36.0                 139.0  0.99788  3.04       0.62   \n",
       "..                   ...                   ...      ...   ...        ...   \n",
       "571                 46.0                 173.0  0.99751  3.14       0.57   \n",
       "572                 61.0                 216.0  0.99520  3.09       0.46   \n",
       "573                 54.0                 162.0  0.99680  3.28       0.50   \n",
       "574                 16.0                  99.0  0.99437  3.26       0.38   \n",
       "575                 47.0                 182.0  0.99538  3.12       0.50   \n",
       "\n",
       "       alcohol  \n",
       "0    10.400000  \n",
       "1    10.500000  \n",
       "2    12.000000  \n",
       "3    12.000000  \n",
       "4    10.033333  \n",
       "..         ...  \n",
       "571  10.200000  \n",
       "572   9.400000  \n",
       "573  10.200000  \n",
       "574  11.500000  \n",
       "575   9.500000  \n",
       "\n",
       "[576 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_train)\n",
    "df1 = pd.read_csv(path_test)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.047</td>\n",
       "      <td>33.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>10.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.062</td>\n",
       "      <td>23.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.49</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.031</td>\n",
       "      <td>20.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.98956</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.33</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.030</td>\n",
       "      <td>43.5</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.49</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>15.7</td>\n",
       "      <td>0.054</td>\n",
       "      <td>36.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.99788</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.34</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.057</td>\n",
       "      <td>46.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.99751</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.045</td>\n",
       "      <td>61.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.99520</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.32</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.047</td>\n",
       "      <td>54.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.32</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.031</td>\n",
       "      <td>16.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.99437</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.38</td>\n",
       "      <td>11.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.054</td>\n",
       "      <td>47.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.99538</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0              7.0              0.15         0.38             2.2      0.047   \n",
       "1              7.2              0.26         0.32            10.4      0.062   \n",
       "2              6.2              0.36         0.38             3.2      0.031   \n",
       "3              8.6              0.36         0.26            11.1      0.030   \n",
       "4              7.4              0.27         0.52            15.7      0.054   \n",
       "..             ...               ...          ...             ...        ...   \n",
       "571            7.3              0.36         0.34            14.8      0.057   \n",
       "572            6.4              0.28         0.41             6.8      0.045   \n",
       "573            6.4              0.24         0.32            14.9      0.047   \n",
       "574            5.5              0.15         0.32            14.0      0.031   \n",
       "575            6.4              0.24         0.26             8.2      0.054   \n",
       "\n",
       "     free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                   33.0                  96.0  0.99280  3.13       0.39   \n",
       "1                   23.0                 114.0  0.99660  3.23       0.49   \n",
       "2                   20.0                  89.0  0.98956  3.06       0.33   \n",
       "3                   43.5                 171.0  0.99480  3.03       0.49   \n",
       "4                   36.0                 139.0  0.99788  3.04       0.62   \n",
       "..                   ...                   ...      ...   ...        ...   \n",
       "571                 46.0                 173.0  0.99751  3.14       0.57   \n",
       "572                 61.0                 216.0  0.99520  3.09       0.46   \n",
       "573                 54.0                 162.0  0.99680  3.28       0.50   \n",
       "574                 16.0                  99.0  0.99437  3.26       0.38   \n",
       "575                 47.0                 182.0  0.99538  3.12       0.50   \n",
       "\n",
       "       alcohol  \n",
       "0    10.400000  \n",
       "1    10.500000  \n",
       "2    12.000000  \n",
       "3    12.000000  \n",
       "4    10.033333  \n",
       "..         ...  \n",
       "571  10.200000  \n",
       "572   9.400000  \n",
       "573  10.200000  \n",
       "574  11.500000  \n",
       "575   9.500000  \n",
       "\n",
       "[576 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=df.drop_duplicates()\n",
    "df_test=df1.drop_duplicates()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.091</td>\n",
       "      <td>42.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.99380</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.037</td>\n",
       "      <td>34.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.57</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.053</td>\n",
       "      <td>54.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.99610</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.048</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.98953</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.37</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.034</td>\n",
       "      <td>5.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.99256</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.030</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.99300</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.048</td>\n",
       "      <td>19.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.99270</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.43</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.029</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.99118</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.50</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.030</td>\n",
       "      <td>32.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.98913</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.33</td>\n",
       "      <td>13.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.021</td>\n",
       "      <td>31.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.98919</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.49</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1725 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               6.4              0.17         0.34             1.5      0.091   \n",
       "1               8.0              0.42         0.36             5.0      0.037   \n",
       "2               6.7              0.27         0.25             8.0      0.053   \n",
       "3               5.2              0.21         0.31             1.7      0.048   \n",
       "4               7.6              0.48         0.37             1.2      0.034   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1720            6.9              0.39         0.22             4.3      0.030   \n",
       "1721            6.4              0.34         0.10             1.1      0.048   \n",
       "1722            7.0              0.53         0.43             6.1      0.029   \n",
       "1723            5.9              0.17         0.29             3.1      0.030   \n",
       "1724            5.5              0.34         0.26             2.2      0.021   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    42.0                 135.0  0.99380  3.25       0.49   \n",
       "1                    34.0                 101.0  0.99200  3.13       0.57   \n",
       "2                    54.0                 202.0  0.99610  3.22       0.43   \n",
       "3                    17.0                  61.0  0.98953  3.24       0.37   \n",
       "4                     5.0                  57.0  0.99256  3.05       0.54   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1720                 10.0                 102.0  0.99300  3.00       0.87   \n",
       "1721                 19.0                  84.0  0.99270  3.21       0.38   \n",
       "1722                  6.0                  76.0  0.99118  3.08       0.50   \n",
       "1723                 32.0                 123.0  0.98913  3.41       0.33   \n",
       "1724                 31.0                 119.0  0.98919  3.55       0.49   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.6        1  \n",
       "1        12.3        1  \n",
       "2         9.3        0  \n",
       "3        12.0        1  \n",
       "4        10.4        0  \n",
       "...       ...      ...  \n",
       "1720     11.6        0  \n",
       "1721      9.8        0  \n",
       "1722     12.5        1  \n",
       "1723     13.7        1  \n",
       "1724     13.0        1  \n",
       "\n",
       "[1725 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['quality'] = (df_train['quality'] >= 7).astype(int)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data=df_train.drop(['quality'],axis=1)\n",
    "df_target=df_train.quality\n",
    "X_train,X_test,y_train,y_test=train_test_split(df_data,df_target,random_state=12)\n",
    "knk = KNeighborsClassifier()\n",
    "knk.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.3,\n",
       "            train_size=0.6),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;, MinMaxScaler()),\n",
       "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
       "             param_grid=[{&#x27;clf__penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                          &#x27;clf__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;,\n",
       "                                          &#x27;sag&#x27;, &#x27;saga&#x27;],\n",
       "                          &#x27;preprocessing&#x27;: [MinMaxScaler(), StandardScaler(),\n",
       "                                            RobustScaler(), Normalizer()]},\n",
       "                         {&#x27;clf__penalty&#x27;: [&#x27;l1&#x27;], &#x27;clf__solver&#x27;: [&#x27;liblinear&#x27;],\n",
       "                          &#x27;preprocessing&#x27;: [MinMaxScaler(), StandardScaler(),\n",
       "                                            RobustScaler(), Normalizer()]},\n",
       "                         {&#x27;clf__penalty&#x27;: [&#x27;none&#x27;],\n",
       "                          &#x27;clf__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;],\n",
       "                          &#x27;preprocessing&#x27;: [MinMaxScaler(), StandardScaler(),\n",
       "                                            RobustScaler(), Normalizer()]}],\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.3,\n",
       "            train_size=0.6),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;, MinMaxScaler()),\n",
       "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
       "             param_grid=[{&#x27;clf__penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                          &#x27;clf__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;,\n",
       "                                          &#x27;sag&#x27;, &#x27;saga&#x27;],\n",
       "                          &#x27;preprocessing&#x27;: [MinMaxScaler(), StandardScaler(),\n",
       "                                            RobustScaler(), Normalizer()]},\n",
       "                         {&#x27;clf__penalty&#x27;: [&#x27;l1&#x27;], &#x27;clf__solver&#x27;: [&#x27;liblinear&#x27;],\n",
       "                          &#x27;preprocessing&#x27;: [MinMaxScaler(), StandardScaler(),\n",
       "                                            RobustScaler(), Normalizer()]},\n",
       "                         {&#x27;clf__penalty&#x27;: [&#x27;none&#x27;],\n",
       "                          &#x27;clf__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;],\n",
       "                          &#x27;preprocessing&#x27;: [MinMaxScaler(), StandardScaler(),\n",
       "                                            RobustScaler(), Normalizer()]}],\n",
       "             return_train_score=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;, MinMaxScaler()),\n",
       "                (&#x27;clf&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.3,\n",
       "            train_size=0.6),\n",
       "             estimator=Pipeline(steps=[('preprocessing', MinMaxScaler()),\n",
       "                                       ('clf', LogisticRegression())]),\n",
       "             param_grid=[{'clf__penalty': ['l2'],\n",
       "                          'clf__solver': ['newton-cg', 'lbfgs', 'liblinear',\n",
       "                                          'sag', 'saga'],\n",
       "                          'preprocessing': [MinMaxScaler(), StandardScaler(),\n",
       "                                            RobustScaler(), Normalizer()]},\n",
       "                         {'clf__penalty': ['l1'], 'clf__solver': ['liblinear'],\n",
       "                          'preprocessing': [MinMaxScaler(), StandardScaler(),\n",
       "                                            RobustScaler(), Normalizer()]},\n",
       "                         {'clf__penalty': ['none'],\n",
       "                          'clf__solver': ['lbfgs', 'newton-cg'],\n",
       "                          'preprocessing': [MinMaxScaler(), StandardScaler(),\n",
       "                                            RobustScaler(), Normalizer()]}],\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('preprocessing', MinMaxScaler()), \n",
    "                 ('clf',           LogisticRegression())])\n",
    "\n",
    "cv = StratifiedShuffleSplit(test_size = .3, train_size = .6, n_splits = 5, random_state = 42)\n",
    "scaling = [ MinMaxScaler(), StandardScaler(),RobustScaler(), Normalizer()]\n",
    "\n",
    "param_grid =[\n",
    "    {'preprocessing': scaling,'clf__penalty': ['l2'], \n",
    "         'clf__solver': ['newton-cg' ,'lbfgs', 'liblinear', 'sag', 'saga']},\n",
    "    {'preprocessing': scaling,'clf__penalty': ['l1'], \n",
    "         'clf__solver': ['liblinear']},\n",
    "    {'preprocessing': scaling,'clf__penalty': ['none'], \n",
    "         'clf__solver': ['lbfgs','newton-cg']}\n",
    "    ]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv = cv, return_train_score = True)\n",
    "grid.fit(X_train, y_train)\n",
    "grid    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>9</th>\n",
       "      <th>21</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>8</th>\n",
       "      <th>20</th>\n",
       "      <th>27</th>\n",
       "      <th>23</th>\n",
       "      <th>11</th>\n",
       "      <th>3</th>\n",
       "      <th>7</th>\n",
       "      <th>15</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.008265</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.006666</td>\n",
       "      <td>0.009197</td>\n",
       "      <td>0.006819</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.033946</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>0.00635</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>0.01448</td>\n",
       "      <td>0.010595</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.00612</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>0.004442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.00292</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.00013</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.00136</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.00141</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.001423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>...</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>none</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__solver</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>...</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>sag</td>\n",
       "      <td>saga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_preprocessing</th>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>...</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'clf__penalty': 'none', 'clf__solver': 'lbfgs...</td>\n",
       "      <td>{'clf__penalty': 'none', 'clf__solver': 'lbfgs...</td>\n",
       "      <td>{'clf__penalty': 'none', 'clf__solver': 'lbfgs...</td>\n",
       "      <td>{'clf__penalty': 'none', 'clf__solver': 'newto...</td>\n",
       "      <td>{'clf__penalty': 'none', 'clf__solver': 'newto...</td>\n",
       "      <td>{'clf__penalty': 'none', 'clf__solver': 'newto...</td>\n",
       "      <td>{'clf__penalty': 'none', 'clf__solver': 'newto...</td>\n",
       "      <td>{'clf__penalty': 'l2', 'clf__solver': 'libline...</td>\n",
       "      <td>{'clf__penalty': 'l1', 'clf__solver': 'libline...</td>\n",
       "      <td>{'clf__penalty': 'l2', 'clf__solver': 'newton-...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'clf__penalty': 'l1', 'clf__solver': 'libline...</td>\n",
       "      <td>{'clf__penalty': 'l2', 'clf__solver': 'libline...</td>\n",
       "      <td>{'clf__penalty': 'l1', 'clf__solver': 'libline...</td>\n",
       "      <td>{'clf__penalty': 'none', 'clf__solver': 'lbfgs...</td>\n",
       "      <td>{'clf__penalty': 'l1', 'clf__solver': 'libline...</td>\n",
       "      <td>{'clf__penalty': 'l2', 'clf__solver': 'libline...</td>\n",
       "      <td>{'clf__penalty': 'l2', 'clf__solver': 'newton-...</td>\n",
       "      <td>{'clf__penalty': 'l2', 'clf__solver': 'lbfgs',...</td>\n",
       "      <td>{'clf__penalty': 'l2', 'clf__solver': 'sag', '...</td>\n",
       "      <td>{'clf__penalty': 'l2', 'clf__solver': 'saga', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.78866</td>\n",
       "      <td>0.78866</td>\n",
       "      <td>0.78866</td>\n",
       "      <td>0.78866</td>\n",
       "      <td>0.78866</td>\n",
       "      <td>0.78866</td>\n",
       "      <td>0.798969</td>\n",
       "      <td>0.791237</td>\n",
       "      <td>0.78866</td>\n",
       "      <td>0.791237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786082</td>\n",
       "      <td>0.780928</td>\n",
       "      <td>0.786082</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.626289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.780928</td>\n",
       "      <td>0.780928</td>\n",
       "      <td>0.778351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.757732</td>\n",
       "      <td>0.755155</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.626289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.760309</td>\n",
       "      <td>0.760309</td>\n",
       "      <td>0.757732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760309</td>\n",
       "      <td>0.780928</td>\n",
       "      <td>0.770619</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.636598</td>\n",
       "      <td>0.634021</td>\n",
       "      <td>0.631443</td>\n",
       "      <td>0.631443</td>\n",
       "      <td>0.631443</td>\n",
       "      <td>0.631443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.757732</td>\n",
       "      <td>0.757732</td>\n",
       "      <td>0.757732</td>\n",
       "      <td>0.757732</td>\n",
       "      <td>0.757732</td>\n",
       "      <td>0.757732</td>\n",
       "      <td>0.752577</td>\n",
       "      <td>0.760309</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.760309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757732</td>\n",
       "      <td>0.757732</td>\n",
       "      <td>0.744845</td>\n",
       "      <td>0.729381</td>\n",
       "      <td>0.652062</td>\n",
       "      <td>0.631443</td>\n",
       "      <td>0.631443</td>\n",
       "      <td>0.631443</td>\n",
       "      <td>0.631443</td>\n",
       "      <td>0.631443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.775773</td>\n",
       "      <td>0.780928</td>\n",
       "      <td>0.778351</td>\n",
       "      <td>0.778351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778351</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.778351</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.641753</td>\n",
       "      <td>0.634021</td>\n",
       "      <td>0.634021</td>\n",
       "      <td>0.634021</td>\n",
       "      <td>0.634021</td>\n",
       "      <td>0.634021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.775258</td>\n",
       "      <td>0.775258</td>\n",
       "      <td>0.775258</td>\n",
       "      <td>0.775258</td>\n",
       "      <td>0.775258</td>\n",
       "      <td>0.775258</td>\n",
       "      <td>0.774742</td>\n",
       "      <td>0.774742</td>\n",
       "      <td>0.774227</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771134</td>\n",
       "      <td>0.770103</td>\n",
       "      <td>0.76701</td>\n",
       "      <td>0.755155</td>\n",
       "      <td>0.635052</td>\n",
       "      <td>0.630412</td>\n",
       "      <td>0.629897</td>\n",
       "      <td>0.629897</td>\n",
       "      <td>0.629897</td>\n",
       "      <td>0.629897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.010886</td>\n",
       "      <td>0.012521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.010488</td>\n",
       "      <td>0.015081</td>\n",
       "      <td>0.016543</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.003093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.763871</td>\n",
       "      <td>0.763871</td>\n",
       "      <td>0.763871</td>\n",
       "      <td>0.763871</td>\n",
       "      <td>0.763871</td>\n",
       "      <td>0.763871</td>\n",
       "      <td>0.756129</td>\n",
       "      <td>0.762581</td>\n",
       "      <td>0.766452</td>\n",
       "      <td>0.762581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763871</td>\n",
       "      <td>0.750968</td>\n",
       "      <td>0.756129</td>\n",
       "      <td>0.745806</td>\n",
       "      <td>0.628387</td>\n",
       "      <td>0.630968</td>\n",
       "      <td>0.630968</td>\n",
       "      <td>0.630968</td>\n",
       "      <td>0.630968</td>\n",
       "      <td>0.630968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75871</td>\n",
       "      <td>0.757419</td>\n",
       "      <td>0.754839</td>\n",
       "      <td>0.75871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757419</td>\n",
       "      <td>0.747097</td>\n",
       "      <td>0.750968</td>\n",
       "      <td>0.745806</td>\n",
       "      <td>0.646452</td>\n",
       "      <td>0.629677</td>\n",
       "      <td>0.630968</td>\n",
       "      <td>0.630968</td>\n",
       "      <td>0.630968</td>\n",
       "      <td>0.630968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.752258</td>\n",
       "      <td>0.752258</td>\n",
       "      <td>0.752258</td>\n",
       "      <td>0.752258</td>\n",
       "      <td>0.752258</td>\n",
       "      <td>0.752258</td>\n",
       "      <td>0.745806</td>\n",
       "      <td>0.749677</td>\n",
       "      <td>0.747097</td>\n",
       "      <td>0.749677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745806</td>\n",
       "      <td>0.749677</td>\n",
       "      <td>0.743226</td>\n",
       "      <td>0.730323</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.633548</td>\n",
       "      <td>0.633548</td>\n",
       "      <td>0.633548</td>\n",
       "      <td>0.633548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>0.766452</td>\n",
       "      <td>0.766452</td>\n",
       "      <td>0.766452</td>\n",
       "      <td>0.766452</td>\n",
       "      <td>0.766452</td>\n",
       "      <td>0.766452</td>\n",
       "      <td>0.771613</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.756129</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756129</td>\n",
       "      <td>0.750968</td>\n",
       "      <td>0.747097</td>\n",
       "      <td>0.748387</td>\n",
       "      <td>0.629677</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.628387</td>\n",
       "      <td>0.628387</td>\n",
       "      <td>0.628387</td>\n",
       "      <td>0.628387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>0.756129</td>\n",
       "      <td>0.756129</td>\n",
       "      <td>0.756129</td>\n",
       "      <td>0.756129</td>\n",
       "      <td>0.756129</td>\n",
       "      <td>0.756129</td>\n",
       "      <td>0.763871</td>\n",
       "      <td>0.757419</td>\n",
       "      <td>0.753548</td>\n",
       "      <td>0.756129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753548</td>\n",
       "      <td>0.749677</td>\n",
       "      <td>0.743226</td>\n",
       "      <td>0.749677</td>\n",
       "      <td>0.623226</td>\n",
       "      <td>0.624516</td>\n",
       "      <td>0.628387</td>\n",
       "      <td>0.628387</td>\n",
       "      <td>0.628387</td>\n",
       "      <td>0.628387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.759742</td>\n",
       "      <td>0.759742</td>\n",
       "      <td>0.759742</td>\n",
       "      <td>0.759742</td>\n",
       "      <td>0.759742</td>\n",
       "      <td>0.759742</td>\n",
       "      <td>0.759226</td>\n",
       "      <td>0.757419</td>\n",
       "      <td>0.755613</td>\n",
       "      <td>0.757419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755355</td>\n",
       "      <td>0.749677</td>\n",
       "      <td>0.748129</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.63071</td>\n",
       "      <td>0.628645</td>\n",
       "      <td>0.630452</td>\n",
       "      <td>0.630452</td>\n",
       "      <td>0.630452</td>\n",
       "      <td>0.630452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.008543</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.001931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    24  \\\n",
       "mean_fit_time                                                 0.008265   \n",
       "std_fit_time                                                  0.000682   \n",
       "mean_score_time                                               0.001268   \n",
       "std_score_time                                                 0.00006   \n",
       "param_clf__penalty                                                none   \n",
       "param_clf__solver                                                lbfgs   \n",
       "param_preprocessing                                     MinMaxScaler()   \n",
       "params               {'clf__penalty': 'none', 'clf__solver': 'lbfgs...   \n",
       "split0_test_score                                              0.78866   \n",
       "split1_test_score                                             0.783505   \n",
       "split2_test_score                                             0.762887   \n",
       "split3_test_score                                             0.757732   \n",
       "split4_test_score                                             0.783505   \n",
       "mean_test_score                                               0.775258   \n",
       "std_test_score                                                0.012457   \n",
       "rank_test_score                                                      1   \n",
       "split0_train_score                                            0.763871   \n",
       "split1_train_score                                                0.76   \n",
       "split2_train_score                                            0.752258   \n",
       "split3_train_score                                            0.766452   \n",
       "split4_train_score                                            0.756129   \n",
       "mean_train_score                                              0.759742   \n",
       "std_train_score                                               0.005122   \n",
       "\n",
       "                                                                    25  \\\n",
       "mean_fit_time                                                 0.005155   \n",
       "std_fit_time                                                  0.000174   \n",
       "mean_score_time                                               0.001215   \n",
       "std_score_time                                                 0.00005   \n",
       "param_clf__penalty                                                none   \n",
       "param_clf__solver                                                lbfgs   \n",
       "param_preprocessing                                   StandardScaler()   \n",
       "params               {'clf__penalty': 'none', 'clf__solver': 'lbfgs...   \n",
       "split0_test_score                                              0.78866   \n",
       "split1_test_score                                             0.783505   \n",
       "split2_test_score                                             0.762887   \n",
       "split3_test_score                                             0.757732   \n",
       "split4_test_score                                             0.783505   \n",
       "mean_test_score                                               0.775258   \n",
       "std_test_score                                                0.012457   \n",
       "rank_test_score                                                      1   \n",
       "split0_train_score                                            0.763871   \n",
       "split1_train_score                                                0.76   \n",
       "split2_train_score                                            0.752258   \n",
       "split3_train_score                                            0.766452   \n",
       "split4_train_score                                            0.756129   \n",
       "mean_train_score                                              0.759742   \n",
       "std_train_score                                               0.005122   \n",
       "\n",
       "                                                                    26  \\\n",
       "mean_fit_time                                                 0.006666   \n",
       "std_fit_time                                                  0.000214   \n",
       "mean_score_time                                               0.001245   \n",
       "std_score_time                                                0.000037   \n",
       "param_clf__penalty                                                none   \n",
       "param_clf__solver                                                lbfgs   \n",
       "param_preprocessing                                     RobustScaler()   \n",
       "params               {'clf__penalty': 'none', 'clf__solver': 'lbfgs...   \n",
       "split0_test_score                                              0.78866   \n",
       "split1_test_score                                             0.783505   \n",
       "split2_test_score                                             0.762887   \n",
       "split3_test_score                                             0.757732   \n",
       "split4_test_score                                             0.783505   \n",
       "mean_test_score                                               0.775258   \n",
       "std_test_score                                                0.012457   \n",
       "rank_test_score                                                      1   \n",
       "split0_train_score                                            0.763871   \n",
       "split1_train_score                                                0.76   \n",
       "split2_train_score                                            0.752258   \n",
       "split3_train_score                                            0.766452   \n",
       "split4_train_score                                            0.756129   \n",
       "mean_train_score                                              0.759742   \n",
       "std_train_score                                               0.005122   \n",
       "\n",
       "                                                                    28  \\\n",
       "mean_fit_time                                                 0.009197   \n",
       "std_fit_time                                                  0.001047   \n",
       "mean_score_time                                                0.00136   \n",
       "std_score_time                                                0.000146   \n",
       "param_clf__penalty                                                none   \n",
       "param_clf__solver                                            newton-cg   \n",
       "param_preprocessing                                     MinMaxScaler()   \n",
       "params               {'clf__penalty': 'none', 'clf__solver': 'newto...   \n",
       "split0_test_score                                              0.78866   \n",
       "split1_test_score                                             0.783505   \n",
       "split2_test_score                                             0.762887   \n",
       "split3_test_score                                             0.757732   \n",
       "split4_test_score                                             0.783505   \n",
       "mean_test_score                                               0.775258   \n",
       "std_test_score                                                0.012457   \n",
       "rank_test_score                                                      1   \n",
       "split0_train_score                                            0.763871   \n",
       "split1_train_score                                                0.76   \n",
       "split2_train_score                                            0.752258   \n",
       "split3_train_score                                            0.766452   \n",
       "split4_train_score                                            0.756129   \n",
       "mean_train_score                                              0.759742   \n",
       "std_train_score                                               0.005122   \n",
       "\n",
       "                                                                    29  \\\n",
       "mean_fit_time                                                 0.006819   \n",
       "std_fit_time                                                  0.000191   \n",
       "mean_score_time                                               0.001315   \n",
       "std_score_time                                                0.000152   \n",
       "param_clf__penalty                                                none   \n",
       "param_clf__solver                                            newton-cg   \n",
       "param_preprocessing                                   StandardScaler()   \n",
       "params               {'clf__penalty': 'none', 'clf__solver': 'newto...   \n",
       "split0_test_score                                              0.78866   \n",
       "split1_test_score                                             0.783505   \n",
       "split2_test_score                                             0.762887   \n",
       "split3_test_score                                             0.757732   \n",
       "split4_test_score                                             0.783505   \n",
       "mean_test_score                                               0.775258   \n",
       "std_test_score                                                0.012457   \n",
       "rank_test_score                                                      1   \n",
       "split0_train_score                                            0.763871   \n",
       "split1_train_score                                                0.76   \n",
       "split2_train_score                                            0.752258   \n",
       "split3_train_score                                            0.766452   \n",
       "split4_train_score                                            0.756129   \n",
       "mean_train_score                                              0.759742   \n",
       "std_train_score                                               0.005122   \n",
       "\n",
       "                                                                    30  \\\n",
       "mean_fit_time                                                 0.008763   \n",
       "std_fit_time                                                  0.000398   \n",
       "mean_score_time                                               0.001272   \n",
       "std_score_time                                                0.000025   \n",
       "param_clf__penalty                                                none   \n",
       "param_clf__solver                                            newton-cg   \n",
       "param_preprocessing                                     RobustScaler()   \n",
       "params               {'clf__penalty': 'none', 'clf__solver': 'newto...   \n",
       "split0_test_score                                              0.78866   \n",
       "split1_test_score                                             0.783505   \n",
       "split2_test_score                                             0.762887   \n",
       "split3_test_score                                             0.757732   \n",
       "split4_test_score                                             0.783505   \n",
       "mean_test_score                                               0.775258   \n",
       "std_test_score                                                0.012457   \n",
       "rank_test_score                                                      1   \n",
       "split0_train_score                                            0.763871   \n",
       "split1_train_score                                                0.76   \n",
       "split2_train_score                                            0.752258   \n",
       "split3_train_score                                            0.766452   \n",
       "split4_train_score                                            0.756129   \n",
       "mean_train_score                                              0.759742   \n",
       "std_train_score                                               0.005122   \n",
       "\n",
       "                                                                    31  \\\n",
       "mean_fit_time                                                 0.033946   \n",
       "std_fit_time                                                  0.002854   \n",
       "mean_score_time                                                0.00141   \n",
       "std_score_time                                                0.000056   \n",
       "param_clf__penalty                                                none   \n",
       "param_clf__solver                                            newton-cg   \n",
       "param_preprocessing                                       Normalizer()   \n",
       "params               {'clf__penalty': 'none', 'clf__solver': 'newto...   \n",
       "split0_test_score                                             0.798969   \n",
       "split1_test_score                                             0.783505   \n",
       "split2_test_score                                             0.762887   \n",
       "split3_test_score                                             0.752577   \n",
       "split4_test_score                                             0.775773   \n",
       "mean_test_score                                               0.774742   \n",
       "std_test_score                                                0.016104   \n",
       "rank_test_score                                                      7   \n",
       "split0_train_score                                            0.756129   \n",
       "split1_train_score                                             0.75871   \n",
       "split2_train_score                                            0.745806   \n",
       "split3_train_score                                            0.771613   \n",
       "split4_train_score                                            0.763871   \n",
       "mean_train_score                                              0.759226   \n",
       "std_train_score                                               0.008543   \n",
       "\n",
       "                                                                    9   \\\n",
       "mean_fit_time                                                 0.003016   \n",
       "std_fit_time                                                  0.000051   \n",
       "mean_score_time                                               0.001132   \n",
       "std_score_time                                                 0.00005   \n",
       "param_clf__penalty                                                  l2   \n",
       "param_clf__solver                                            liblinear   \n",
       "param_preprocessing                                   StandardScaler()   \n",
       "params               {'clf__penalty': 'l2', 'clf__solver': 'libline...   \n",
       "split0_test_score                                             0.791237   \n",
       "split1_test_score                                             0.780928   \n",
       "split2_test_score                                             0.760309   \n",
       "split3_test_score                                             0.760309   \n",
       "split4_test_score                                             0.780928   \n",
       "mean_test_score                                               0.774742   \n",
       "std_test_score                                                0.012371   \n",
       "rank_test_score                                                      8   \n",
       "split0_train_score                                            0.762581   \n",
       "split1_train_score                                            0.757419   \n",
       "split2_train_score                                            0.749677   \n",
       "split3_train_score                                                0.76   \n",
       "split4_train_score                                            0.757419   \n",
       "mean_train_score                                              0.757419   \n",
       "std_train_score                                               0.004318   \n",
       "\n",
       "                                                                    21  \\\n",
       "mean_fit_time                                                  0.00635   \n",
       "std_fit_time                                                  0.001075   \n",
       "mean_score_time                                               0.001383   \n",
       "std_score_time                                                0.000041   \n",
       "param_clf__penalty                                                  l1   \n",
       "param_clf__solver                                            liblinear   \n",
       "param_preprocessing                                   StandardScaler()   \n",
       "params               {'clf__penalty': 'l1', 'clf__solver': 'libline...   \n",
       "split0_test_score                                              0.78866   \n",
       "split1_test_score                                             0.780928   \n",
       "split2_test_score                                             0.760309   \n",
       "split3_test_score                                             0.762887   \n",
       "split4_test_score                                             0.778351   \n",
       "mean_test_score                                               0.774227   \n",
       "std_test_score                                                0.010886   \n",
       "rank_test_score                                                      9   \n",
       "split0_train_score                                            0.766452   \n",
       "split1_train_score                                            0.754839   \n",
       "split2_train_score                                            0.747097   \n",
       "split3_train_score                                            0.756129   \n",
       "split4_train_score                                            0.753548   \n",
       "mean_train_score                                              0.755613   \n",
       "std_train_score                                               0.006247   \n",
       "\n",
       "                                                                    1   ...  \\\n",
       "mean_fit_time                                                 0.006662  ...   \n",
       "std_fit_time                                                  0.000683  ...   \n",
       "mean_score_time                                               0.001129  ...   \n",
       "std_score_time                                                0.000027  ...   \n",
       "param_clf__penalty                                                  l2  ...   \n",
       "param_clf__solver                                            newton-cg  ...   \n",
       "param_preprocessing                                   StandardScaler()  ...   \n",
       "params               {'clf__penalty': 'l2', 'clf__solver': 'newton-...  ...   \n",
       "split0_test_score                                             0.791237  ...   \n",
       "split1_test_score                                             0.778351  ...   \n",
       "split2_test_score                                             0.757732  ...   \n",
       "split3_test_score                                             0.760309  ...   \n",
       "split4_test_score                                             0.778351  ...   \n",
       "mean_test_score                                               0.773196  ...   \n",
       "std_test_score                                                0.012521  ...   \n",
       "rank_test_score                                                     10  ...   \n",
       "split0_train_score                                            0.762581  ...   \n",
       "split1_train_score                                             0.75871  ...   \n",
       "split2_train_score                                            0.749677  ...   \n",
       "split3_train_score                                                0.76  ...   \n",
       "split4_train_score                                            0.756129  ...   \n",
       "mean_train_score                                              0.757419  ...   \n",
       "std_train_score                                               0.004395  ...   \n",
       "\n",
       "                                                                    22  \\\n",
       "mean_fit_time                                                 0.006647   \n",
       "std_fit_time                                                  0.001395   \n",
       "mean_score_time                                               0.001283   \n",
       "std_score_time                                                 0.00011   \n",
       "param_clf__penalty                                                  l1   \n",
       "param_clf__solver                                            liblinear   \n",
       "param_preprocessing                                     RobustScaler()   \n",
       "params               {'clf__penalty': 'l1', 'clf__solver': 'libline...   \n",
       "split0_test_score                                             0.786082   \n",
       "split1_test_score                                             0.773196   \n",
       "split2_test_score                                             0.760309   \n",
       "split3_test_score                                             0.757732   \n",
       "split4_test_score                                             0.778351   \n",
       "mean_test_score                                               0.771134   \n",
       "std_test_score                                                0.010738   \n",
       "rank_test_score                                                     23   \n",
       "split0_train_score                                            0.763871   \n",
       "split1_train_score                                            0.757419   \n",
       "split2_train_score                                            0.745806   \n",
       "split3_train_score                                            0.756129   \n",
       "split4_train_score                                            0.753548   \n",
       "mean_train_score                                              0.755355   \n",
       "std_train_score                                               0.005862   \n",
       "\n",
       "                                                                    8   \\\n",
       "mean_fit_time                                                 0.002963   \n",
       "std_fit_time                                                  0.000152   \n",
       "mean_score_time                                               0.001142   \n",
       "std_score_time                                                0.000037   \n",
       "param_clf__penalty                                                  l2   \n",
       "param_clf__solver                                            liblinear   \n",
       "param_preprocessing                                     MinMaxScaler()   \n",
       "params               {'clf__penalty': 'l2', 'clf__solver': 'libline...   \n",
       "split0_test_score                                             0.780928   \n",
       "split1_test_score                                             0.757732   \n",
       "split2_test_score                                             0.780928   \n",
       "split3_test_score                                             0.757732   \n",
       "split4_test_score                                             0.773196   \n",
       "mean_test_score                                               0.770103   \n",
       "std_test_score                                                0.010488   \n",
       "rank_test_score                                                     24   \n",
       "split0_train_score                                            0.750968   \n",
       "split1_train_score                                            0.747097   \n",
       "split2_train_score                                            0.749677   \n",
       "split3_train_score                                            0.750968   \n",
       "split4_train_score                                            0.749677   \n",
       "mean_train_score                                              0.749677   \n",
       "std_train_score                                               0.001413   \n",
       "\n",
       "                                                                    20  \\\n",
       "mean_fit_time                                                 0.010999   \n",
       "std_fit_time                                                   0.00292   \n",
       "mean_score_time                                               0.001342   \n",
       "std_score_time                                                0.000081   \n",
       "param_clf__penalty                                                  l1   \n",
       "param_clf__solver                                            liblinear   \n",
       "param_preprocessing                                     MinMaxScaler()   \n",
       "params               {'clf__penalty': 'l1', 'clf__solver': 'libline...   \n",
       "split0_test_score                                             0.786082   \n",
       "split1_test_score                                             0.755155   \n",
       "split2_test_score                                             0.770619   \n",
       "split3_test_score                                             0.744845   \n",
       "split4_test_score                                             0.778351   \n",
       "mean_test_score                                                0.76701   \n",
       "std_test_score                                                0.015081   \n",
       "rank_test_score                                                     25   \n",
       "split0_train_score                                            0.756129   \n",
       "split1_train_score                                            0.750968   \n",
       "split2_train_score                                            0.743226   \n",
       "split3_train_score                                            0.747097   \n",
       "split4_train_score                                            0.743226   \n",
       "mean_train_score                                              0.748129   \n",
       "std_train_score                                               0.004924   \n",
       "\n",
       "                                                                    27  \\\n",
       "mean_fit_time                                                  0.01448   \n",
       "std_fit_time                                                  0.000644   \n",
       "mean_score_time                                               0.001572   \n",
       "std_score_time                                                0.000267   \n",
       "param_clf__penalty                                                none   \n",
       "param_clf__solver                                                lbfgs   \n",
       "param_preprocessing                                       Normalizer()   \n",
       "params               {'clf__penalty': 'none', 'clf__solver': 'lbfgs...   \n",
       "split0_test_score                                             0.773196   \n",
       "split1_test_score                                                 0.75   \n",
       "split2_test_score                                             0.773196   \n",
       "split3_test_score                                             0.729381   \n",
       "split4_test_score                                                 0.75   \n",
       "mean_test_score                                               0.755155   \n",
       "std_test_score                                                0.016543   \n",
       "rank_test_score                                                     26   \n",
       "split0_train_score                                            0.745806   \n",
       "split1_train_score                                            0.745806   \n",
       "split2_train_score                                            0.730323   \n",
       "split3_train_score                                            0.748387   \n",
       "split4_train_score                                            0.749677   \n",
       "mean_train_score                                                 0.744   \n",
       "std_train_score                                               0.007001   \n",
       "\n",
       "                                                                    23  \\\n",
       "mean_fit_time                                                 0.010595   \n",
       "std_fit_time                                                  0.002403   \n",
       "mean_score_time                                               0.001459   \n",
       "std_score_time                                                0.000022   \n",
       "param_clf__penalty                                                  l1   \n",
       "param_clf__solver                                            liblinear   \n",
       "param_preprocessing                                       Normalizer()   \n",
       "params               {'clf__penalty': 'l1', 'clf__solver': 'libline...   \n",
       "split0_test_score                                             0.626289   \n",
       "split1_test_score                                             0.618557   \n",
       "split2_test_score                                             0.636598   \n",
       "split3_test_score                                             0.652062   \n",
       "split4_test_score                                             0.641753   \n",
       "mean_test_score                                               0.635052   \n",
       "std_test_score                                                0.011709   \n",
       "rank_test_score                                                     27   \n",
       "split0_train_score                                            0.628387   \n",
       "split1_train_score                                            0.646452   \n",
       "split2_train_score                                            0.625806   \n",
       "split3_train_score                                            0.629677   \n",
       "split4_train_score                                            0.623226   \n",
       "mean_train_score                                               0.63071   \n",
       "std_train_score                                               0.008177   \n",
       "\n",
       "                                                                    11  \\\n",
       "mean_fit_time                                                 0.002821   \n",
       "std_fit_time                                                   0.00013   \n",
       "mean_score_time                                               0.001237   \n",
       "std_score_time                                                0.000039   \n",
       "param_clf__penalty                                                  l2   \n",
       "param_clf__solver                                            liblinear   \n",
       "param_preprocessing                                       Normalizer()   \n",
       "params               {'clf__penalty': 'l2', 'clf__solver': 'libline...   \n",
       "split0_test_score                                             0.626289   \n",
       "split1_test_score                                             0.626289   \n",
       "split2_test_score                                             0.634021   \n",
       "split3_test_score                                             0.631443   \n",
       "split4_test_score                                             0.634021   \n",
       "mean_test_score                                               0.630412   \n",
       "std_test_score                                                0.003496   \n",
       "rank_test_score                                                     28   \n",
       "split0_train_score                                            0.630968   \n",
       "split1_train_score                                            0.629677   \n",
       "split2_train_score                                            0.632258   \n",
       "split3_train_score                                            0.625806   \n",
       "split4_train_score                                            0.624516   \n",
       "mean_train_score                                              0.628645   \n",
       "std_train_score                                               0.002987   \n",
       "\n",
       "                                                                    3   \\\n",
       "mean_fit_time                                                 0.004881   \n",
       "std_fit_time                                                  0.000058   \n",
       "mean_score_time                                               0.001274   \n",
       "std_score_time                                                0.000091   \n",
       "param_clf__penalty                                                  l2   \n",
       "param_clf__solver                                            newton-cg   \n",
       "param_preprocessing                                       Normalizer()   \n",
       "params               {'clf__penalty': 'l2', 'clf__solver': 'newton-...   \n",
       "split0_test_score                                             0.626289   \n",
       "split1_test_score                                             0.626289   \n",
       "split2_test_score                                             0.631443   \n",
       "split3_test_score                                             0.631443   \n",
       "split4_test_score                                             0.634021   \n",
       "mean_test_score                                               0.629897   \n",
       "std_test_score                                                0.003093   \n",
       "rank_test_score                                                     29   \n",
       "split0_train_score                                            0.630968   \n",
       "split1_train_score                                            0.630968   \n",
       "split2_train_score                                            0.633548   \n",
       "split3_train_score                                            0.628387   \n",
       "split4_train_score                                            0.628387   \n",
       "mean_train_score                                              0.630452   \n",
       "std_train_score                                               0.001931   \n",
       "\n",
       "                                                                    7   \\\n",
       "mean_fit_time                                                  0.00612   \n",
       "std_fit_time                                                  0.000136   \n",
       "mean_score_time                                               0.001321   \n",
       "std_score_time                                                 0.00005   \n",
       "param_clf__penalty                                                  l2   \n",
       "param_clf__solver                                                lbfgs   \n",
       "param_preprocessing                                       Normalizer()   \n",
       "params               {'clf__penalty': 'l2', 'clf__solver': 'lbfgs',...   \n",
       "split0_test_score                                             0.626289   \n",
       "split1_test_score                                             0.626289   \n",
       "split2_test_score                                             0.631443   \n",
       "split3_test_score                                             0.631443   \n",
       "split4_test_score                                             0.634021   \n",
       "mean_test_score                                               0.629897   \n",
       "std_test_score                                                0.003093   \n",
       "rank_test_score                                                     29   \n",
       "split0_train_score                                            0.630968   \n",
       "split1_train_score                                            0.630968   \n",
       "split2_train_score                                            0.633548   \n",
       "split3_train_score                                            0.628387   \n",
       "split4_train_score                                            0.628387   \n",
       "mean_train_score                                              0.630452   \n",
       "std_train_score                                               0.001931   \n",
       "\n",
       "                                                                    15  \\\n",
       "mean_fit_time                                                 0.004095   \n",
       "std_fit_time                                                  0.000135   \n",
       "mean_score_time                                               0.001256   \n",
       "std_score_time                                                0.000033   \n",
       "param_clf__penalty                                                  l2   \n",
       "param_clf__solver                                                  sag   \n",
       "param_preprocessing                                       Normalizer()   \n",
       "params               {'clf__penalty': 'l2', 'clf__solver': 'sag', '...   \n",
       "split0_test_score                                             0.626289   \n",
       "split1_test_score                                             0.626289   \n",
       "split2_test_score                                             0.631443   \n",
       "split3_test_score                                             0.631443   \n",
       "split4_test_score                                             0.634021   \n",
       "mean_test_score                                               0.629897   \n",
       "std_test_score                                                0.003093   \n",
       "rank_test_score                                                     29   \n",
       "split0_train_score                                            0.630968   \n",
       "split1_train_score                                            0.630968   \n",
       "split2_train_score                                            0.633548   \n",
       "split3_train_score                                            0.628387   \n",
       "split4_train_score                                            0.628387   \n",
       "mean_train_score                                              0.630452   \n",
       "std_train_score                                               0.001931   \n",
       "\n",
       "                                                                    19  \n",
       "mean_fit_time                                                 0.004442  \n",
       "std_fit_time                                                   0.00014  \n",
       "mean_score_time                                               0.001423  \n",
       "std_score_time                                                0.000218  \n",
       "param_clf__penalty                                                  l2  \n",
       "param_clf__solver                                                 saga  \n",
       "param_preprocessing                                       Normalizer()  \n",
       "params               {'clf__penalty': 'l2', 'clf__solver': 'saga', ...  \n",
       "split0_test_score                                             0.626289  \n",
       "split1_test_score                                             0.626289  \n",
       "split2_test_score                                             0.631443  \n",
       "split3_test_score                                             0.631443  \n",
       "split4_test_score                                             0.634021  \n",
       "mean_test_score                                               0.629897  \n",
       "std_test_score                                                0.003093  \n",
       "rank_test_score                                                     29  \n",
       "split0_train_score                                            0.630968  \n",
       "split1_train_score                                            0.630968  \n",
       "split2_train_score                                            0.633548  \n",
       "split3_train_score                                            0.628387  \n",
       "split4_train_score                                            0.628387  \n",
       "mean_train_score                                              0.630452  \n",
       "std_train_score                                               0.001931  \n",
       "\n",
       "[23 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result = pd.DataFrame(grid.cv_results_).sort_values([\"rank_test_score\",'std_test_score']).T\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = grid_result.index[grid_result.index.str.endswith(\"_test_score\")][:-3]\n",
    "tabl = grid_result.loc[mask].iloc[:,:10]\n",
    "sns.boxplot(data=tabl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__penalty': 'none',\n",
       " 'clf__solver': 'lbfgs',\n",
       " 'preprocessing': MinMaxScaler()}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_['params'][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82       291\n",
      "           1       0.63      0.44      0.52       141\n",
      "\n",
      "    accuracy                           0.73       432\n",
      "   macro avg       0.70      0.66      0.67       432\n",
      "weighted avg       0.72      0.73      0.72       432\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/imachome/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "pipe_best = make_pipeline(Normalizer(), LogisticRegression(solver = 'lbfgs', penalty = 'none') )\n",
    "\n",
    "pipe_best.fit(X_train,y_train)\n",
    "y_pred_best = pipe_best.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок предсказания с использованием тестового набора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка на тренировочном наборе:  0.7432327919566899\n",
      "Оценка на тестовом наборе:  0.7337962962962963\n"
     ]
    }
   ],
   "source": [
    "print('Оценка на тренировочном наборе: ', pipe_best.score(X_train,y_train))\n",
    "print('Оценка на тестовом наборе: ', pipe_best.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Название вектора предсказанных значений  y_predict полученого на основании тестового набора\n",
    "y_predict = pipe_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [576, 432]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score\n\u001b[1;32m      5\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_Y_true.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m matrix\u001b[38;5;241m=\u001b[39mconfusion_matrix(y_true, y_predict)\n\u001b[1;32m      7\u001b[0m ConfusionMatrixDisplay(matrix)\u001b[38;5;241m.\u001b[39mplot();\n\u001b[1;32m      8\u001b[0m precision_score(y_true, y_predict)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    232\u001b[0m     {\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    243\u001b[0m ):\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [576, 432]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "y_true = np.where(pd.read_csv('test_Y_true.csv').values>=7,1,0)\n",
    "matrix=confusion_matrix(y_true, y_predict)\n",
    "ConfusionMatrixDisplay(matrix).plot();\n",
    "precision_score(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики моделей классификации "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "##### Визуал контейнера ###\n",
    "# from sklearn import set_config\n",
    "# set_config(display=\"diagram\")\n",
    "\n",
    "\n",
    "import sklearn\n",
    "#pip install --upgrade scikit-learn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Зачем нам нужна метрика?\n",
    "\n",
    "**Представим себе следующую задачу:** в больницу обращается 90% здоровых людей и 10% больных. Нам выделили квадрилион денег, что бы мы в 90% случаях определяли болен или здоров пациент.\n",
    "\n",
    "Не долго думая мы создали модель самого глубокого обучения в которой, каждому обратившемуся мы говорили  - \"вы здоровы\"! \n",
    "\n",
    "**Профффит!!!** Мы вполнили ТЗ.\n",
    "\n",
    "Я думаю, не нужно объяснять, что сделали мы всем очень плохо, особенно если мы сами прийдем в данное лечебное учреждение ...\n",
    "\n",
    "Давайте разберемся какие метрики существую для решения задач классификации и как их расчитывать и самое главное как их применять в реальных задачах.\n",
    "\n",
    "**Спойлер** Как не смешно, но выбор правильной метрики это задача бизнеса, любому датасатанисту, который хочет добиться успеха в своей области нужно достаточно глубоко вникать в реальную задачу (и часто не слушать окружающих его \"эффективных\" менеджеров), что бы понять какую метрику нужно использовать для решения этой задачи. Часто готовых метрик будет не хватать. В данном курсе, в основном, мы будем учиться искать из условия задачи, какая стандартная метрика лучше всего подходит для решения задачи. \n",
    "\n",
    "\n",
    "Для простоты и удобства сначала, будут построены метрики для бинарной классификации, а затем покажем отличия для многоклассовой классификации.\n",
    "\n",
    "# Стандартные метрики бинарной классиикации\n",
    "\n",
    "[`sklearn.metrics`](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)\n",
    "\n",
    "Для понимания метрик в терминах ошибок классификации запишим матрицу ошибок (*confusion matrix*). Обратите внимание на расположение истиных и ложных строк и столбцов - оно отлично от принятого в математической статистике.\n",
    "\n",
    "\n",
    "|                     | y_pred = 0 | y_pred = 1          |\n",
    "| ----------- |:------------:| ---------------:|\n",
    "| **y_true = 0**       | True Negative (**TN**)     | False Positive (**FP**) |\n",
    "| **y_true = 1**       | False Negative (**FN**)    | True Positive (**TP**)  |\n",
    "\n",
    "Почему именно такая запись? Потому что, именно так выводится данная матрица в библиотеках python, не будем создавать путаницу в теории и практике.\n",
    "\n",
    "## Правильность (Accuracy)\n",
    "\n",
    "[`sklearn.metrics.accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html?highlight=accuracy#sklearn.metrics.accuracy_score)\n",
    "\n",
    "Интуитивно понятной, очевидной и редко используемой метрикой является правильность (accuracy) — доля правильных ответов нашего алгоритма:\n",
    "$$ accuracy = \\frac{TN+TP}{TN+FP +FN+TP}$$\n",
    "\n",
    "|                     | y_pred = 0 | y_pred = 1          |\n",
    "| ----------- |:------------:| ---------------:|\n",
    "| **y_true = 0**       | <span style=\"color:red\">True Negative (**TN**)</span>     | False Positive (**FP**) |\n",
    "| **y_true = 1**       | False Negative (**FN**)    | <span style=\"color:red\">True Positive (**TP**)</span>  |\n",
    "\n",
    "\n",
    "Увы эта мерика бесполезна в задачах с неравными классами, например как в нашей с вами задаче о больнице (0- здоровые, 1 - больные, кстати почему так, а не наоборот?):\n",
    "\n",
    "|                     | y_pred = 0 | y_pred = 1          |\n",
    "| ----------- |:------------:| ---------------:|\n",
    "| **y_true = 0**       | 90     | 0 |\n",
    "| **y_true = 1**       | 10    |  0 |\n",
    "\n",
    "$$ accuracy = \\frac{90+0}{90+10 +0+0}=\\frac{90}{100}=0.9$$\n",
    "\n",
    "А теперь модифицируем задачу:\n",
    "\n",
    "|                     | y_pred = 0 | y_pred = 1          |\n",
    "| ----------- |:------------:| ---------------:|\n",
    "| **y_true = 0**       | 81     | 9 |\n",
    "| **y_true = 1**       | 1    |  9 |\n",
    "\n",
    "$$ accuracy = \\frac{81+9}{81+9 +9+1}=\\frac{90}{100}=0.9$$\n",
    "\n",
    "Результат одинаков, а для больных находим лучше :)\n",
    "\n",
    "## Точность (Precision)\n",
    "\n",
    "[`sklearn.metrics.precision_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\n",
    "\n",
    "Давайте посмотрим метрику точности:\n",
    "\n",
    "$$ precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "|                     | y_pred = 0 | y_pred = 1          |\n",
    "| ----------- |:------------:| ---------------:|\n",
    "| **y_true = 0**       | True Negative (**TN**)     | <span style=\"color:red\">False Positive (**FP**)</span> |\n",
    "| **y_true = 1**       | False Negative (**FN**)    | <span style=\"color:red\">True Positive (**TP**)</span>  |\n",
    "\n",
    "\n",
    "Данная метрика покажет насколько точно мы предсказываем класс 1, есть ли у нас мусор в предсказанном классе 1 из класса 0. Ошибки в самом классе 1 нас не интересуют.\n",
    "\n",
    "|                     | y_pred = 0 | y_pred = 1          |\n",
    "| ----------- |:------------:| ---------------:|\n",
    "| **y_true = 0**       | 90     | 0 |\n",
    "| **y_true = 1**       | 10    |  0 |\n",
    "\n",
    "$$ precision = \\frac{0}{0+0} = 0$$\n",
    "\n",
    "|                     | y_pred = 0 | y_pred = 1          |\n",
    "| ----------- |:------------:| ---------------:|\n",
    "| **y_true = 0**       | 81     | 9 |\n",
    "| **y_true = 1**       | 1    |  9 |\n",
    "\n",
    "$$ precision = \\frac{9}{9+9}=\\frac{9}{18}=0.5$$\n",
    "\n",
    "\n",
    "Точность можно интерпретировать как долю объектов, названных классификатором положительными и при этом **действительно** являющимися положительными.\n",
    "\n",
    "## Полнота (recall)\n",
    "\n",
    "[`sklearn.metrics.recall_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html?highlight=sklearn+metrics+recall_score#sklearn.metrics.recall_score)\n",
    "\n",
    "$$ recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "|                     | y_pred = 0 | y_pred = 1          |\n",
    "| ----------- |:------------:| ---------------:|\n",
    "| **y_true = 0**       | True Negative (**TN**)     | False Positive (**FP**)|\n",
    "| **y_true = 1**       | <span style=\"color:red\">False Negative (**FN**)</span>     | <span style=\"color:red\">True Positive (**TP**)</span>  |\n",
    "\n",
    "\n",
    "Данная метрика покажет насколько полно мы предсказываем класс 1 и какую часть в этом предсказании мы теряем. Важное замечание - мусор появившийся от ошибочных предсказаний 0 как 1 нас не волнует. \n",
    "\n",
    "|                     | y_pred = 0 | y_pred = 1          |\n",
    "| ----------- |:------------:| ---------------:|\n",
    "| **y_true = 0**       | 90     | 0 |\n",
    "| **y_true = 1**       | 10    |  0 |\n",
    "\n",
    "$$ precision = \\frac{0}{0+10} = 0$$\n",
    "\n",
    "|                     | y_pred = 0 | y_pred = 1          |\n",
    "| ----------- |:------------:| ---------------:|\n",
    "| **y_true = 0**       | 81     | 9 |\n",
    "| **y_true = 1**       | 1    |  9 |\n",
    "\n",
    "$$ precision = \\frac{9}{1+9}=\\frac{9}{10}=0.9$$\n",
    "\n",
    "Данная метрика демонстрирует способность алгоритма обнаруживать позитивный класс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод:\n",
    "\n",
    "Если мы решаем задачу об эффективной больнице, то тот класс, который мы ищем как целевой показатель должен иметь номер 1 (в бинарной классификации). Именно под его поиск \"заточены\" метрики. Очевидно, что в нашей задаче - это поиск больных пациентов.\n",
    "\n",
    "- метрика правильности не подходит, так как не дает картину хорошего качества поиска больных в выборке.\n",
    "- метрика точности не подходит так как мы не знаем сколько больных мы пропустили.\n",
    "- метрика полноты позволит понять насколько хорошо мы находим больных и минимизация FN позволит улучшить качество обнаружения больных, но при этом (с точки зрания поиска больного), мы можем не беспокоится о неверных диагнозах (FP) - потом до обследуем :), поэтому это лучшая метрика, однако есть НО ...\n",
    "\n",
    "Однако для страховой медецины, бюджета и т.п. это не оцень удачный подход, мы слишком наразумно тратим финансы. Поэтому нам нужна метрика, которая сбалансирует FN и  FP при поиске TP\n",
    "\n",
    "## Метрика $F_1$\n",
    "\n",
    "[`sklearn.metrics.f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html?highlight=sklearn+metrics+f1_score#sklearn.metrics.f1_score)\n",
    "\n",
    "Метрика $F_1$ представляет собой балас между точностью и полнотой в поиске положительного класса. Расчитывается следующим образом:\n",
    "\n",
    "$$F_1 = 2 \\frac{precission\\cdot recall}{precission+recall}=\\frac{2}{\\dfrac{1}{precission}+\n",
    "\\dfrac{1}{recall}}=\n",
    "\\frac{TP}{TP+\\dfrac{1}{2}(FP+FN)}\n",
    "$$\n",
    "\n",
    "|                     | y_pred = 0 | y_pred = 1          |\n",
    "| ----------- |:------------:| ---------------:|\n",
    "| **y_true = 0**       | True Negative (**TN**)     | <span style=\"color:red\">False Positive (**FP**)</span> |\n",
    "| **y_true = 1**       | <span style=\"color:red\">False Negative (**FN**)</span>    | <span style=\"color:red\">True Positive (**TP**)</span>  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|                     | y_pred = 0 | y_pred = 1          |\n",
    "| ----------- |:------------:| ---------------:|\n",
    "| **y_true = 0**       | 90     | 10 |\n",
    "| **y_true = 1**       | 0    |  0 |\n",
    "\n",
    "$$ F_1 = \\frac{0}{0+0.5(0+10)} = 0$$\n",
    "\n",
    "|                     | y_pred = 0 | y_pred = 1          |\n",
    "| ----------- |:------------:| ---------------:|\n",
    "| **y_true = 0**       | 81     | 9 |\n",
    "| **y_true = 1**       | 1    |  9 |\n",
    "\n",
    "$$ precision = \\frac{9}{9+0.5(1+9)}=\\frac{9}{14} = 0.64$$\n",
    "\n",
    "С точки зрания страховой результат явно не очень ... слишком много расходов не нужных расходов ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Средне гармоническая метрика $F_\\beta$\n",
    "\n",
    "[`sklearn.metrics.fbeta_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html?highlight=sklearn+metrics+fbeta_score#sklearn.metrics.fbeta_score)\n",
    "\n",
    "$\\beta$ в данном случае определяет вес точности в метрике, и при $\\beta = 1$ это среднее гармоническое (с множителем 2, чтобы в случае precision = 1 и recall = 1 иметь $F_1 = 1$)\n",
    "F-мера достигает максимума при полноте и точности, равными единице, и близка к нулю, если один из аргументов близок к нулю.\n",
    "\n",
    "$$F_\\beta = (1+\\beta^2) \\frac{precission\\cdot recall}{\\beta^2 precission+recall}\\\\\n",
    "F_\\beta  = \\frac{(1+\\beta^2)TP}{(1+\\beta^2)TP+\\beta^2FN+FP)}\n",
    "$$\n",
    "\n",
    "Параметр бета определяет вес полноты в ценке. $\\beta < 1$ придает больший вес точности, если же $\\beta > 1$ по вес распределяетя в сторону полноты:\n",
    "- $\\beta \\rightarrow 0$ учитывается только точность; \n",
    "- $\\beta \\rightarrow +\\infty$ только полнота.\n",
    "\n",
    "## Логистическая функция потерь\n",
    "\n",
    "[`sklearn.metrics.log_loss`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html?highlight=sklearn+metrics+log_loss#sklearn.metrics.log_loss)\n",
    "\n",
    "Интуитивно можно представить минимизацию `log_loss` как задачу максимизации `accuracy` путем штрафа за неверные предсказания. Однако необходимо отметить, что `log_loss` крайне сильно штрафует за уверенность классификатора в неверном ответе.\n",
    "\n",
    "Данная метрика нечасто выступает в бизнес-требованиях, но часто — в задачах на kaggle.\n",
    "\n",
    "$$ log\\_loss = \\frac{1}{n}\\sum_{i=1}^n\\left(y_i \\ln(p_i)+(1-y_i)\\ln(1-p_i)\\right)$$\n",
    "\n",
    "где $y_i \\in {0,1}$ - значение класса из `y_true`, $p_i = Pr(y_i=1)$ вероятность классификации $y_i$ как 1. \n",
    "\n",
    "Важный коментарий! Возможно применять если алгоритм реализует `predict_proba` - вероятность классификации, как например [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC AUC, PR AUC\n",
    "\n",
    "**Важный термин!** AUC это сокращение от Area Under Curve - площадь под кривой. Употреблять отдельно без указания конкретной кривой - странно, но увы вчтречается постоянно, жаргон ...\n",
    "\n",
    "Мы только, что говорили, что алгоритмы (большинство) предсказывают `predict_proba` - вероятность классификации заданного класса. Вопрос а какой порог можно поставить чтобы отдель эти классы и что от этого меняется?\n",
    "\n",
    "Естественным и близким кажется порог, равный 0.5, но он не всегла является оптимальным, например при дисбалансе классов.\n",
    "\n",
    "Одним из способов оценить модель в целом, не привязываясь к конкретному порогу, является ROC AUC — площадь (Area Under Curve) под кривой ошибок (Receiver Operating Characteristic curve ). Данная кривая представляет из себя линию от (0,0) до (1,1) в координатах True Positive Rate (TPR) и False Positive Rate (FPR):\n",
    "\n",
    "$$ TPR = \\frac{TP}{TP+FN}$$\n",
    "$$ FPR = \\frac{FP}{TP+TN}$$\n",
    "\n",
    "TPR нам уже известна, это полнота, а FPR показывает, какую долю из объектов negative класса алгоритм предсказал неверно.\n",
    "\n",
    "В идеальном случае, когда классификатор не делает ошибок (FPR = 0, TPR = 1) мы получим площадь под кривой, равную единице. \n",
    "\n",
    "В противном случае, когда классификатор случайно выдает вероятности классов, AUC-ROC будет стремиться к 0.5, так как классификатор будет выдавать одинаковое количество TP и FP.\n",
    "\n",
    "<img src=\"Pict/rocauc.png\" width=\"600\" />\n",
    "\n",
    "Каждая точка на графике соответствует выбору некоторого порога. Площадь под кривой в данном случае показывает качество алгоритма (больше — лучше), кроме этого, важной является крутизна самой кривой — мы хотим максимизировать TPR, минимизируя FPR, а значит, наша кривая в идеале должна стремиться к точке (0,1).\n",
    "\n",
    "ROC AUC оценивает устойчивочть алгоритма, так как позволяет оценить качество всех порогов сразу.  \n",
    "\n",
    "Давайте подробно разберем принцип построения кривой ROC-AUC.\n",
    "\n",
    "Пусть алгоритм выдал оценки (степень уверенности классификаторв - `predict_proba`, не путать с вероятностью правильной классификации), как показано в табл. 1.   \n",
    "Упорядочим строки табл. 1 по убыванию ответов алгоритма – получим табл. 2. Очевтдно, что в идеале её столбец «класс» тоже станет упорядочен (сначала идут 1, потом 0); в самом худшем случае – порядок будет обратный (сначала 0, потом 1); в случае «слепого угадывания» будет случайное распределение 0 и 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Pict/table.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы нарисовать ROC-кривую, надо взять единичный квадрат на координатной плоскости, см. ррисунок ниже, разбить его на $m$ равных частей горизонтальными линиями и на $n$ – вертикальными, где $m$ – число 1 среди  меток теста (в нашем примере $m=3$), $n$ – число нулей ($n=4$). В результате квадрат разбивается сеткой на $m\\times n$ блоков.\n",
    "\n",
    "Теперь будем просматривать строки табл. 2 сверху вниз и прорисовывать на сетке линии, переходя их одного узла в другой. Стартуем из точки $(0, 0)$. Если значение метки класса в просматриваемой строке 1, то делаем шаг вверх; если 0, то делаем шаг вправо. Ясно, что в итоге мы попадём в точку $(1, 1)$, т.к. сделаем в сумме $m$ шагов вверх и $n$ шагов вправо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Pict/roc.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рисунке (справа) показан путь для нашего примера – это и является ROC-кривой. Важный момент: если у нескольких объектов значения оценок равны, то мы делаем шаг в точку, которая на $a$ блоков выше и $b$ блоков правее, где $a$ – число единиц в группе объектов с одним значением метки, $b$ – число нулей в ней.   \n",
    "В частности, если все объекты имеют одинаковую метку, то мы сразу шагаем из точки $(0, 0)$ в точку $(1, 1)$ (покажите самостоятельно, почему это так)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Критерий AUC-ROC устойчив к несбалансированным классам \n",
    "(но: увы, не всё так однозначно) и может быть интерпретирован как вероятность того, что случайно выбранный positive объект будет проранжирован классификатором выше (будет иметь более высокую вероятность быть positive), чем случайно выбранный negative объект.\n",
    "\n",
    "Рассмотрим следующую задачу: нам необходимо выбрать 100 релевантных документов из 1 миллиона документов. Мы намашинлернили два алгоритма:\n",
    "\n",
    "**Пример 1** возвращает 100 документов, 90 из которых релевантны. Таким образом,\n",
    "\n",
    "$$ TPR = \\frac{TP}{TP + FN} = \\frac{90}{90 + 10} = 0.9$$\n",
    "\n",
    "$$ FPR = \\frac{FP}{FP + TN} = \\frac{10}{10 + 999890} = 0.00001$$\n",
    "\n",
    "\n",
    "**Пример 2** возвращает 2000 документов, 90 из которых релевантны. Таким образом,\n",
    "\n",
    "$$ TPR = \\frac{TP}{TP + FN} = \\frac{90}{90 + 10} = 0.9$$\n",
    "\n",
    "\n",
    "$$ FPR = \\frac{FP}{FP + TN} = \\frac{1910}{1910 + 997990} = 0.00191$$\n",
    "\n",
    "\n",
    "Скорее всего, мы бы выбрали первый алгоритм, который выдает очень мало FP на фоне своего конкурента. Но разница в FRP между этими двумя алгоритмами крайне мала — всего 0.0019. Это является следствием того, что ROC AUC измеряет долю FP относительно TN и в задачах, где нам не так важен второй (больший) класс, может давать не совсем адекватную картину при сравнении алгоритмов.\n",
    "\n",
    "Для того чтобы поправить положение, вернемся к полноте и точности :\n",
    "\n",
    "**Пример 1**\n",
    "\n",
    "$$ precision = \\frac{TP}{TP + FP} = 90/(90 + 10) = 0.9 $$\n",
    "\n",
    "$$ recall = \\frac{TP}{TP + FN} = 90/(90 + 10) = 0.9 $$\n",
    "\n",
    "\n",
    "**Пример 2**\n",
    "\n",
    "$$ precision = \\frac{TP}{TP + FP} = \\frac{90}{90 + 1910} = 0.045 $$\n",
    "\n",
    "$$ recall = \\frac{TP}{TP + FN} = \\frac{90}{90 + 10} = 0.9 $$\n",
    "\n",
    "\n",
    "Здесь уже заметна существенная разница между двумя алгоритмами — 0.855 в точности.\n",
    "\n",
    "Precision и recall также используют для построения кривой PR AUC находят площадь под ней. При этом наилучшая точка находится в в точке с координатами (1, 1)\n",
    "\n",
    "<img src=\"Pict/pr.png\" width=\"600\" />\n",
    "\n",
    "**Важная ссылка!** За подробностями о взаимоотношениях ROC AUC и PR AUC можно обратиться [сюда](https://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики имбалансных классов\n",
    "\n",
    "**Стоит только начать и сразу можно потеряться**\n",
    "\n",
    "### Специализированная библиотека\n",
    "\n",
    "Специализированная [библиотека](https://imbalanced-learn.org/stable/index.html) для понимания степени, меры и глубины проблем ...\n",
    "\n",
    "Увы на это у нас нехватит времени ...\n",
    "\n",
    "### Стандартный способ\n",
    "\n",
    "[`sklearn.metrics.balanced_accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score)\n",
    "\n",
    "Можно использовать для многоклассовой классификации. Для бинарной нужно внимательно смотреть на условия конкретной задачи.\n",
    "\n",
    "$$ balanced\\_accuracy = \\frac{1}{2}\\left(\\frac{TP}{TP+FN}+\\frac{TN}{TN+FP}\\right) $$\n",
    "\n",
    "Важная ссылка! [Метрики и примеры](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мультиклассовая классификация и метрики\n",
    "\n",
    "Пройдемся только по самым основным понятиям, более глубоко будет время вернемся в конце курса.\n",
    "\n",
    "исходник [тут](https://towardsdatascience.com/micro-macro-weighted-averages-of-f1-score-clearly-explained-b603420b292f)\n",
    "\n",
    "<img src=\"Pict/w05.png\" width=\"600\" />\n",
    "\n",
    "Посчитали\n",
    "\n",
    "<img src=\"Pict/w04.png\" width=\"600\" />\n",
    "\n",
    "Вспомним как считается остальное:\n",
    "\n",
    "<img src=\"Pict/w06.png\" width=\"600\" />\n",
    "\n",
    "`Macro averaging` единое среднее для классов f1\n",
    "\n",
    "<img src=\"Pict/w02.png\" width=\"600\" />\n",
    "\n",
    "`Micro averaging` сумма TP, нормированная на TP+1/2(FP+FN) для каждого класса. Важно!  'micro avg' == 'accuracy' если учитываются все классы, если же указать только подмножество классов, то в выводе появится строчка с 'micro avg' вместо 'accuracy'.\n",
    "\n",
    "<img src=\"Pict/w01.png\" width=\"600\" />\n",
    "\n",
    "`Weighted Average` средневзвешенная оценка с учетом долей классов\n",
    "\n",
    "<img src=\"Pict/w03.png\" width=\"600\" />\n",
    "\n",
    "\n",
    "Как считается можно посмотреть [тут](https://www.educative.io/answers/what-is-the-difference-between-micro-and-macro-averaging)\n",
    "\n",
    "В чем же отличие macro, micro и weighted:\n",
    "\n",
    "- \"macro\" просто вычисляет среднее значение показателей, придавая каждому классу одинаковый вес. В задачах, где редкие классы важны, макро-усреднение может быть средством выделения их значимости. С другой стороны, предположение, что все классы одинаково важны, часто неверно, так что макро-усреднение будет чрезмерно подчеркивать обычно низкую значимость для редкого класса.\n",
    "\n",
    "- \"weighted\" учитывает дисбаланс классов, вычисляя среднее значение показателей, в которых оценка каждого класса взвешивается по его присутствию в истинной выборке данных.\n",
    "\n",
    "- \"micro\" дает каждой строке данных, соотнесенной с классом, равный вклад в общую метрику. Вместо того, чтобы суммировать метрику для каждого класса, мы суммируем составные части метрик (TP, FN, FP) для каждого класса, для расчета общего частного. Микро-усреднение может быть предпочтительным в мультиклассовой классификации, когда классы с наибольшим количеством строк (данных) следует игнорировать.\n",
    "\n",
    "## Вишенка на торте\n",
    "\n",
    "Еще про метрики классификации - [крайне полезная таблица](https://en.wikipedia.org/wiki/Template:Diagnostic_testing_diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

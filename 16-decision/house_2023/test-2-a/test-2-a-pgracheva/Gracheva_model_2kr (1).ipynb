{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Внимание!!! Важно, что бы файлы с данными и исполняемый файл находились в одной папке, \n",
    "# тогда пути к тестовым и тренировочным наборам будут содержать только имена файлов.\n",
    "# \n",
    "# В пути к тренировочным и тестовым данным запрежается использовать абсалютную адресацию, \n",
    "# то есть адресацию, в которой присутствуют имена папок. Путь должен содержать только имя файла.\n",
    "#\n",
    "# Напоминание: под моделью машинного обучения понимаются все действия с исходными данными, \n",
    "# которые необходимо произвести, что бы сопоставить признаки целевому значению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 1 (библиотеки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный блок в области 1 выполняется преподавателем\n",
    "# \n",
    "# данный блок предназначен только для подключения необходимых библиотек\n",
    "# запрещается подключать библиотеки в других блоках\n",
    "# запрещается скрывать предупреждения системы\n",
    "# установка дополнительных библиотек размещается прямо здесь (обязательно закоментированы)\n",
    "# pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder,LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures, QuantileTransformer, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, TransformedTargetRegressor\\\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import log_loss, zero_one_loss, accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, Lars, OrthogonalMatchingPursuit, SGDRegressor, LinearRegression\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster import hierarchy\n",
    "from collections import defaultdict\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 2 (выполнение лучшей модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный блок(и) в области 2 выполняется преподавателем\n",
    "#\n",
    "# В области находится одна, единственная, итоговая модель машинного обучения с однозначными, \n",
    "# зафиксированными параметрами\n",
    "#\n",
    "# В данной области категорически запрещается искать, выбирать, улучшать, оптимизировать, \n",
    "# тюниговать и т.д. модель машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к тренировочному набору\n",
    "path_train = 'train_house_A.csv' # содержит только имя файла, без имен папок\n",
    "# Путь к тестовому набору\n",
    "path_test  = 'test_house_A.csv' # содержит только имя файла, без имен папок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path_train)\n",
    "df_test = pd.read_csv(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5320000</td>\n",
       "      <td>0.405623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.061169</td>\n",
       "      <td>-0.741051</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>1.361397</td>\n",
       "      <td>1.221991</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.478408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245475</td>\n",
       "      <td>-0.263991</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.222962</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>1.804941</td>\n",
       "      <td>-0.126718</td>\n",
       "      <td>0.271470</td>\n",
       "      <td>1.391006</td>\n",
       "      <td>-0.141322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3465000</td>\n",
       "      <td>0.405623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.826890</td>\n",
       "      <td>-0.867066</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.964205</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.478408</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.444928</td>\n",
       "      <td>-0.263991</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.222962</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.554035</td>\n",
       "      <td>-0.126718</td>\n",
       "      <td>-1.010746</td>\n",
       "      <td>0.617421</td>\n",
       "      <td>-0.141322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3500000</td>\n",
       "      <td>0.405623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963310</td>\n",
       "      <td>-1.676106</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.692084</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.478408</td>\n",
       "      <td>...</td>\n",
       "      <td>1.578828</td>\n",
       "      <td>-0.263991</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.222962</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.554035</td>\n",
       "      <td>-0.126718</td>\n",
       "      <td>-1.237596</td>\n",
       "      <td>1.483005</td>\n",
       "      <td>-0.141322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3570000</td>\n",
       "      <td>0.405623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242611</td>\n",
       "      <td>0.193424</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.696696</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>1.307431</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.675466</td>\n",
       "      <td>-0.263991</td>\n",
       "      <td>-1.308863</td>\n",
       "      <td>1.222962</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.554035</td>\n",
       "      <td>0.417348</td>\n",
       "      <td>-0.987324</td>\n",
       "      <td>1.134657</td>\n",
       "      <td>-0.141322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4130000</td>\n",
       "      <td>0.405623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.740827</td>\n",
       "      <td>-0.684767</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.239163</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.478408</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.347578</td>\n",
       "      <td>-0.263991</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>-0.091662</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.554035</td>\n",
       "      <td>-0.108582</td>\n",
       "      <td>0.838006</td>\n",
       "      <td>0.360062</td>\n",
       "      <td>-0.141322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>4550000</td>\n",
       "      <td>0.405623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.008081</td>\n",
       "      <td>1.658059</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.696696</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.478408</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.341446</td>\n",
       "      <td>-0.263991</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>-1.406286</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.554035</td>\n",
       "      <td>-0.126718</td>\n",
       "      <td>-1.532214</td>\n",
       "      <td>1.329553</td>\n",
       "      <td>-0.141322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>5250000</td>\n",
       "      <td>0.405623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.592671</td>\n",
       "      <td>-0.816078</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>1.361397</td>\n",
       "      <td>-0.622901</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.478408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144745</td>\n",
       "      <td>-0.263991</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.222962</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>1.804941</td>\n",
       "      <td>-0.126718</td>\n",
       "      <td>-1.320247</td>\n",
       "      <td>0.041976</td>\n",
       "      <td>-0.141322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>5950000</td>\n",
       "      <td>0.405623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.458904</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>1.361397</td>\n",
       "      <td>0.640850</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.478408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.734544</td>\n",
       "      <td>-0.263991</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>-1.406286</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>1.804941</td>\n",
       "      <td>-0.126718</td>\n",
       "      <td>-0.017405</td>\n",
       "      <td>-1.353372</td>\n",
       "      <td>-0.141322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>4319000</td>\n",
       "      <td>0.405623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.973555</td>\n",
       "      <td>0.522287</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>1.361397</td>\n",
       "      <td>-0.515897</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>1.307431</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282323</td>\n",
       "      <td>-0.263991</td>\n",
       "      <td>-1.308863</td>\n",
       "      <td>-1.406286</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.554035</td>\n",
       "      <td>0.195188</td>\n",
       "      <td>-0.131175</td>\n",
       "      <td>1.363075</td>\n",
       "      <td>-0.141322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>4200000</td>\n",
       "      <td>0.405623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.811005</td>\n",
       "      <td>1.333801</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>0.299545</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.478408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085282</td>\n",
       "      <td>-0.263991</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>-0.091662</td>\n",
       "      <td>4.560702</td>\n",
       "      <td>-0.554035</td>\n",
       "      <td>-0.126718</td>\n",
       "      <td>-0.428933</td>\n",
       "      <td>0.101230</td>\n",
       "      <td>-0.141322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       price         0    1         2         3         4         5         6  \\\n",
       "0    5320000  0.405623  0.0 -0.061169 -0.741051 -0.223185  1.361397  1.221991   \n",
       "1    3465000  0.405623  0.0 -0.826890 -0.867066 -0.223185 -0.734539 -0.964205   \n",
       "2    3500000  0.405623  0.0 -0.963310 -1.676106 -0.223185 -0.734539 -0.692084   \n",
       "3    3570000  0.405623  0.0  0.242611  0.193424 -0.223185 -0.734539 -0.696696   \n",
       "4    4130000  0.405623  0.0 -0.740827 -0.684767 -0.223185 -0.734539 -0.239163   \n",
       "..       ...       ...  ...       ...       ...       ...       ...       ...   \n",
       "403  4550000  0.405623  0.0  1.008081  1.658059 -0.223185 -0.734539 -0.696696   \n",
       "404  5250000  0.405623  0.0  1.592671 -0.816078 -0.223185  1.361397 -0.622901   \n",
       "405  5950000  0.405623  0.0  0.582200  0.458904 -0.223185  1.361397  0.640850   \n",
       "406  4319000  0.405623  0.0 -0.973555  0.522287 -0.223185  1.361397 -0.515897   \n",
       "407  4200000  0.405623  0.0 -0.811005  1.333801 -0.223185 -0.734539  0.299545   \n",
       "\n",
       "            7         8  ...        19        20        21        22  \\\n",
       "0   -0.570187 -0.478408  ...  0.245475 -0.263991  0.047278  1.222962   \n",
       "1   -0.570187 -0.478408  ... -1.444928 -0.263991  0.047278  1.222962   \n",
       "2   -0.570187 -0.478408  ...  1.578828 -0.263991  0.047278  1.222962   \n",
       "3   -0.570187  1.307431  ... -1.675466 -0.263991 -1.308863  1.222962   \n",
       "4   -0.570187 -0.478408  ... -1.347578 -0.263991  1.403419 -0.091662   \n",
       "..        ...       ...  ...       ...       ...       ...       ...   \n",
       "403 -0.570187 -0.478408  ... -1.341446 -0.263991  0.047278 -1.406286   \n",
       "404 -0.570187 -0.478408  ... -0.144745 -0.263991  0.047278  1.222962   \n",
       "405 -0.570187 -0.478408  ... -0.734544 -0.263991  0.047278 -1.406286   \n",
       "406 -0.570187  1.307431  ... -0.282323 -0.263991 -1.308863 -1.406286   \n",
       "407 -0.570187 -0.478408  ... -0.085282 -0.263991  0.047278 -0.091662   \n",
       "\n",
       "           23        24        25        26        27        28  \n",
       "0   -0.219265  1.804941 -0.126718  0.271470  1.391006 -0.141322  \n",
       "1   -0.219265 -0.554035 -0.126718 -1.010746  0.617421 -0.141322  \n",
       "2   -0.219265 -0.554035 -0.126718 -1.237596  1.483005 -0.141322  \n",
       "3   -0.219265 -0.554035  0.417348 -0.987324  1.134657 -0.141322  \n",
       "4   -0.219265 -0.554035 -0.108582  0.838006  0.360062 -0.141322  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "403 -0.219265 -0.554035 -0.126718 -1.532214  1.329553 -0.141322  \n",
       "404 -0.219265  1.804941 -0.126718 -1.320247  0.041976 -0.141322  \n",
       "405 -0.219265  1.804941 -0.126718 -0.017405 -1.353372 -0.141322  \n",
       "406 -0.219265 -0.554035  0.195188 -0.131175  1.363075 -0.141322  \n",
       "407  4.560702 -0.554035 -0.126718 -0.428933  0.101230 -0.141322  \n",
       "\n",
       "[408 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# НАЗВАНИЯ ОСТАВШИХСЯ КОЛОНОК: '2', '3', '4', '5', '6', '7', '12', '13', '14', '16', '17', '23', '25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>23</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5320000</td>\n",
       "      <td>-0.061169</td>\n",
       "      <td>-0.741051</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>1.361397</td>\n",
       "      <td>1.221991</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.929397</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>-0.142607</td>\n",
       "      <td>1.472618</td>\n",
       "      <td>-0.280781</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.126718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3465000</td>\n",
       "      <td>-0.826890</td>\n",
       "      <td>-0.867066</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.964205</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.929397</td>\n",
       "      <td>-0.805741</td>\n",
       "      <td>0.307755</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>1.311928</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.126718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3500000</td>\n",
       "      <td>-0.963310</td>\n",
       "      <td>-1.676106</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.692084</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>-0.805741</td>\n",
       "      <td>-1.033235</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>0.470806</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.126718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3570000</td>\n",
       "      <td>0.242611</td>\n",
       "      <td>0.193424</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.696696</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.929397</td>\n",
       "      <td>-0.805741</td>\n",
       "      <td>-1.119627</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>-1.039726</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>0.417348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4130000</td>\n",
       "      <td>-0.740827</td>\n",
       "      <td>-0.684767</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.239163</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>-0.805741</td>\n",
       "      <td>0.232269</td>\n",
       "      <td>1.472618</td>\n",
       "      <td>1.747297</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.108582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>4550000</td>\n",
       "      <td>1.008081</td>\n",
       "      <td>1.658059</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.696696</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>-0.805741</td>\n",
       "      <td>2.948326</td>\n",
       "      <td>1.472618</td>\n",
       "      <td>1.491291</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.126718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>5250000</td>\n",
       "      <td>1.592671</td>\n",
       "      <td>-0.816078</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>1.361397</td>\n",
       "      <td>-0.622901</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>0.355976</td>\n",
       "      <td>1.138751</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>-0.269301</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.126718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>5950000</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.458904</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>1.361397</td>\n",
       "      <td>0.640850</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.929397</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>-0.653206</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>-1.273605</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.126718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>4319000</td>\n",
       "      <td>-0.973555</td>\n",
       "      <td>0.522287</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>1.361397</td>\n",
       "      <td>-0.515897</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.929397</td>\n",
       "      <td>-0.805741</td>\n",
       "      <td>0.330239</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>1.109630</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>0.195188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>4200000</td>\n",
       "      <td>-0.811005</td>\n",
       "      <td>1.333801</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>0.299545</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.929397</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>-0.713499</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>-0.196861</td>\n",
       "      <td>4.560702</td>\n",
       "      <td>-0.126718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       price         2         3         4         5         6         7  \\\n",
       "0    5320000 -0.061169 -0.741051 -0.223185  1.361397  1.221991 -0.570187   \n",
       "1    3465000 -0.826890 -0.867066 -0.223185 -0.734539 -0.964205 -0.570187   \n",
       "2    3500000 -0.963310 -1.676106 -0.223185 -0.734539 -0.692084 -0.570187   \n",
       "3    3570000  0.242611  0.193424 -0.223185 -0.734539 -0.696696 -0.570187   \n",
       "4    4130000 -0.740827 -0.684767 -0.223185 -0.734539 -0.239163 -0.570187   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "403  4550000  1.008081  1.658059 -0.223185 -0.734539 -0.696696 -0.570187   \n",
       "404  5250000  1.592671 -0.816078 -0.223185  1.361397 -0.622901 -0.570187   \n",
       "405  5950000  0.582200  0.458904 -0.223185  1.361397  0.640850 -0.570187   \n",
       "406  4319000 -0.973555  0.522287 -0.223185  1.361397 -0.515897 -0.570187   \n",
       "407  4200000 -0.811005  1.333801 -0.223185 -0.734539  0.299545 -0.570187   \n",
       "\n",
       "           12        13        14        16        17        23        25  \n",
       "0   -0.929397  1.517692 -0.142607  1.472618 -0.280781 -0.219265 -0.126718  \n",
       "1   -0.929397 -0.805741  0.307755 -0.679063  1.311928 -0.219265 -0.126718  \n",
       "2    0.224410 -0.805741 -1.033235 -0.679063  0.470806 -0.219265 -0.126718  \n",
       "3   -0.929397 -0.805741 -1.119627 -0.679063 -1.039726 -0.219265  0.417348  \n",
       "4    0.224410 -0.805741  0.232269  1.472618  1.747297 -0.219265 -0.108582  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "403  0.224410 -0.805741  2.948326  1.472618  1.491291 -0.219265 -0.126718  \n",
       "404  0.224410  0.355976  1.138751 -0.679063 -0.269301 -0.219265 -0.126718  \n",
       "405 -0.929397  1.517692 -0.653206 -0.679063 -1.273605 -0.219265 -0.126718  \n",
       "406 -0.929397 -0.805741  0.330239 -0.679063  1.109630 -0.219265  0.195188  \n",
       "407 -0.929397  1.517692 -0.713499 -0.679063 -0.196861  4.560702 -0.126718  \n",
       "\n",
       "[408 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['1', '8', '21', '20', '28', '0', '24', '22', '10', '15', '27', '9', '18', '26', '11', '19']\n",
    "df_train = df_train.drop(columns_to_drop, axis=1)\n",
    "df_test = df_test.drop(columns_to_drop, axis=1)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target=df_train['price']\n",
    "df_data=df_train.drop('price', axis=1)\n",
    "random_seed=53\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data, df_target, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>23</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.931702</td>\n",
       "      <td>1.196496</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>0.488647</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>2.532024</td>\n",
       "      <td>-0.805741</td>\n",
       "      <td>0.294621</td>\n",
       "      <td>1.472618</td>\n",
       "      <td>-1.203803</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>0.785727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.788580</td>\n",
       "      <td>-1.263275</td>\n",
       "      <td>1.472449</td>\n",
       "      <td>1.361397</td>\n",
       "      <td>0.391790</td>\n",
       "      <td>3.413810</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>-0.634672</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>0.530364</td>\n",
       "      <td>4.560702</td>\n",
       "      <td>0.666712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.384500</td>\n",
       "      <td>-1.127236</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-1.303204</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>-0.805741</td>\n",
       "      <td>-0.929597</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>-0.574417</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.126718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.642224</td>\n",
       "      <td>-1.519809</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>1.361397</td>\n",
       "      <td>1.169412</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.929397</td>\n",
       "      <td>-0.805741</td>\n",
       "      <td>-0.754375</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>-0.937064</td>\n",
       "      <td>4.560702</td>\n",
       "      <td>-0.126718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.348662</td>\n",
       "      <td>-0.943795</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.486840</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.929397</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>0.628778</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>1.396914</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>0.159484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.037632</td>\n",
       "      <td>-1.153273</td>\n",
       "      <td>0.624632</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>0.391790</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>2.532024</td>\n",
       "      <td>0.355976</td>\n",
       "      <td>-0.725904</td>\n",
       "      <td>1.472618</td>\n",
       "      <td>1.633640</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>0.666712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.458546</td>\n",
       "      <td>0.471874</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.341555</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.929397</td>\n",
       "      <td>0.355976</td>\n",
       "      <td>-1.248529</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>-1.424502</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.019038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>-0.525244</td>\n",
       "      <td>-1.760731</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>0.336443</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.929397</td>\n",
       "      <td>-0.805741</td>\n",
       "      <td>0.575127</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>-1.386457</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>-0.852140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>-0.861678</td>\n",
       "      <td>-0.642180</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.300045</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>0.355976</td>\n",
       "      <td>-0.149375</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>0.821972</td>\n",
       "      <td>4.560702</td>\n",
       "      <td>-0.070044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-0.210121</td>\n",
       "      <td>-0.220234</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.599839</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.929397</td>\n",
       "      <td>-0.805741</td>\n",
       "      <td>-0.491846</td>\n",
       "      <td>-0.679063</td>\n",
       "      <td>-0.447227</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>0.298334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            2         3         4         5         6         7        12  \\\n",
       "0    0.931702  1.196496 -0.223185 -0.734539  0.488647 -0.570187  2.532024   \n",
       "1    0.788580 -1.263275  1.472449  1.361397  0.391790  3.413810  0.224410   \n",
       "2    0.384500 -1.127236 -0.223185 -0.734539 -1.303204 -0.570187  0.224410   \n",
       "3    0.642224 -1.519809 -0.223185  1.361397  1.169412 -0.570187 -0.929397   \n",
       "4    0.348662 -0.943795 -0.223185 -0.734539 -0.486840 -0.570187 -0.929397   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "132  0.037632 -1.153273  0.624632 -0.734539  0.391790  1.421812  2.532024   \n",
       "133  0.458546  0.471874 -0.223185 -0.734539 -0.341555 -0.570187 -0.929397   \n",
       "134 -0.525244 -1.760731 -0.223185 -0.734539  0.336443 -0.570187 -0.929397   \n",
       "135 -0.861678 -0.642180 -0.223185 -0.734539 -0.300045 -0.570187  0.224410   \n",
       "136 -0.210121 -0.220234 -0.223185 -0.734539 -0.599839 -0.570187 -0.929397   \n",
       "\n",
       "           13        14        16        17        23        25  \n",
       "0   -0.805741  0.294621  1.472618 -1.203803 -0.219265  0.785727  \n",
       "1    1.517692 -0.634672 -0.679063  0.530364  4.560702  0.666712  \n",
       "2   -0.805741 -0.929597 -0.679063 -0.574417 -0.219265 -0.126718  \n",
       "3   -0.805741 -0.754375 -0.679063 -0.937064  4.560702 -0.126718  \n",
       "4    1.517692  0.628778 -0.679063  1.396914 -0.219265  0.159484  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "132  0.355976 -0.725904  1.472618  1.633640 -0.219265  0.666712  \n",
       "133  0.355976 -1.248529 -0.679063 -1.424502 -0.219265 -0.019038  \n",
       "134 -0.805741  0.575127 -0.679063 -1.386457 -0.219265 -0.852140  \n",
       "135  0.355976 -0.149375 -0.679063  0.821972  4.560702 -0.070044  \n",
       "136 -0.805741 -0.491846 -0.679063 -0.447227 -0.219265  0.298334  \n",
       "\n",
       "[137 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок(и) обучения и поверки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=5, regressor__p=1;, score=(train=0.624, test=0.442) total time=   0.0s\n",
      "[CV 2/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=5, regressor__p=1;, score=(train=0.638, test=0.388) total time=   0.0s\n",
      "[CV 3/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=5, regressor__p=1;, score=(train=0.622, test=0.466) total time=   0.0s\n",
      "[CV 4/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=5, regressor__p=1;, score=(train=0.644, test=0.205) total time=   0.0s\n",
      "[CV 5/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=5, regressor__p=1;, score=(train=0.630, test=0.519) total time=   0.0s\n",
      "[CV 1/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=5, regressor__p=4;, score=(train=0.650, test=0.513) total time=   0.0s\n",
      "[CV 2/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=5, regressor__p=4;, score=(train=0.669, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=5, regressor__p=4;, score=(train=0.628, test=0.566) total time=   0.0s\n",
      "[CV 4/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=5, regressor__p=4;, score=(train=0.690, test=0.208) total time=   0.0s\n",
      "[CV 5/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=5, regressor__p=4;, score=(train=0.661, test=0.544) total time=   0.0s\n",
      "[CV 1/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=4;, score=(train=0.247, test=0.225) total time=   0.0s\n",
      "[CV 2/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=4;, score=(train=0.231, test=0.149) total time=   0.0s\n",
      "[CV 3/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=4;, score=(train=0.248, test=0.396) total time=   0.0s\n",
      "[CV 4/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=4;, score=(train=0.316, test=0.169) total time=   0.0s\n",
      "[CV 5/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=4;, score=(train=0.215, test=0.231) total time=   0.0s\n",
      "[CV 1/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=4;, score=(train=0.223, test=0.277) total time=   0.0s\n",
      "[CV 2/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=4;, score=(train=0.212, test=0.243) total time=   0.0s\n",
      "[CV 3/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=4;, score=(train=0.241, test=0.279) total time=   0.0s\n",
      "[CV 4/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=4;, score=(train=0.300, test=-0.010) total time=   0.0s\n",
      "[CV 5/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=4;, score=(train=0.202, test=0.236) total time=   0.0s\n",
      "[CV 1/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=50, regressor__p=1;, score=(train=0.394, test=0.460) total time=   0.0s\n",
      "[CV 2/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=50, regressor__p=1;, score=(train=0.413, test=0.318) total time=   0.0s\n",
      "[CV 3/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=50, regressor__p=1;, score=(train=0.393, test=0.582) total time=   0.0s\n",
      "[CV 4/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=50, regressor__p=1;, score=(train=0.492, test=0.166) total time=   0.0s\n",
      "[CV 5/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=50, regressor__p=1;, score=(train=0.381, test=0.401) total time=   0.0s\n",
      "[CV 1/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=2;, score=(train=0.275, test=0.284) total time=   0.0s\n",
      "[CV 2/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=2;, score=(train=0.270, test=0.182) total time=   0.0s\n",
      "[CV 3/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=2;, score=(train=0.279, test=0.433) total time=   0.0s\n",
      "[CV 4/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=2;, score=(train=0.351, test=0.153) total time=   0.0s\n",
      "[CV 5/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=2;, score=(train=0.243, test=0.259) total time=   0.0s\n",
      "[CV 1/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=20, regressor__p=2;, score=(train=0.441, test=0.420) total time=   0.0s\n",
      "[CV 2/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=20, regressor__p=2;, score=(train=0.470, test=0.415) total time=   0.0s\n",
      "[CV 3/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=20, regressor__p=2;, score=(train=0.441, test=0.491) total time=   0.0s\n",
      "[CV 4/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=20, regressor__p=2;, score=(train=0.501, test=0.151) total time=   0.0s\n",
      "[CV 5/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=20, regressor__p=2;, score=(train=0.433, test=0.424) total time=   0.0s\n",
      "[CV 1/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=2, regressor__p=4;, score=(train=0.786, test=0.348) total time=   0.0s\n",
      "[CV 2/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=2, regressor__p=4;, score=(train=0.763, test=0.480) total time=   0.0s\n",
      "[CV 3/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=2, regressor__p=4;, score=(train=0.769, test=0.413) total time=   0.0s\n",
      "[CV 4/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=2, regressor__p=4;, score=(train=0.801, test=0.159) total time=   0.0s\n",
      "[CV 5/5] END preprocessing=StandardScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=2, regressor__p=4;, score=(train=0.785, test=0.370) total time=   0.0s\n",
      "[CV 1/5] END preprocessing=RobustScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=1;, score=(train=0.218, test=0.240) total time=   0.0s\n",
      "[CV 2/5] END preprocessing=RobustScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=1;, score=(train=0.231, test=0.148) total time=   0.0s\n",
      "[CV 3/5] END preprocessing=RobustScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=1;, score=(train=0.188, test=0.292) total time=   0.0s\n",
      "[CV 4/5] END preprocessing=RobustScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=1;, score=(train=0.292, test=0.154) total time=   0.0s\n",
      "[CV 5/5] END preprocessing=RobustScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=100, regressor__p=1;, score=(train=0.169, test=0.187) total time=   0.0s\n",
      "[CV 1/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=50, regressor__p=3;, score=(train=0.334, test=0.367) total time=   0.0s\n",
      "[CV 2/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=50, regressor__p=3;, score=(train=0.311, test=0.392) total time=   0.0s\n",
      "[CV 3/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=50, regressor__p=3;, score=(train=0.327, test=0.339) total time=   0.0s\n",
      "[CV 4/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=50, regressor__p=3;, score=(train=0.404, test=0.009) total time=   0.0s\n",
      "[CV 5/5] END preprocessing=MinMaxScaler(), regressor=KNeighborsRegressor(), regressor__n_neighbors=50, regressor__p=3;, score=(train=0.327, test=0.325) total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('preprocessing', MinMaxScaler()),\n",
       "                                             ('regressor',\n",
       "                                              KNeighborsRegressor())]),\n",
       "                   param_distributions={'preprocessing': [MinMaxScaler(),\n",
       "                                                          StandardScaler(),\n",
       "                                                          RobustScaler()],\n",
       "                                        'regressor': [KNeighborsRegressor(p=4)],\n",
       "                                        'regressor__n_neighbors': [2, 5, 10, 20,\n",
       "                                                                   50, 100],\n",
       "                                        'regressor__p': array([1, 2, 3, 4])},\n",
       "                   return_train_score=True, verbose=4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('preprocessing', MinMaxScaler()), \n",
    "                 ('regressor',    KNeighborsRegressor())])\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "\n",
    "p = np.arange(1,5)\n",
    "n_neighbors = [2,5,10,20,50,100]\n",
    "scaling = [ MinMaxScaler(), StandardScaler(),RobustScaler()]\n",
    "#weights = ['uniform','distance'] weights=distance использовать не буду, т.к с ним score train=1, т.е идет переобучение\n",
    "param_grid = {\n",
    "    'preprocessing': scaling,\n",
    "    'regressor': [KNeighborsRegressor()],\n",
    "    'regressor__n_neighbors': n_neighbors,\n",
    "    'regressor__p': p,\n",
    "}\n",
    "\n",
    "\n",
    "grid = RandomizedSearchCV(pipe,param_grid, cv=kfold,verbose=4,return_train_score=True)\n",
    "grid.fit(X_train,y_train)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__p': 4, 'regressor__n_neighbors': 5, 'regressor': KNeighborsRegressor(p=4), 'preprocessing': StandardScaler()}\n",
      "0.4622694409293002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21462697603454217"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pr = grid.predict(X_test)\n",
    "mape = mean_absolute_percentage_error(y_test, knn_pr)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок предсказания с использованием тестового набора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5225200736278155\n"
     ]
    }
   ],
   "source": [
    "model =  Pipeline([\n",
    "            ('preprocessing', StandardScaler()), \n",
    "            ('regressor',     KNeighborsRegressor(n_neighbors=5, p=4))\n",
    "            ])\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6482000., 5859000., 3129000., 4991000., 3346000., 2912000.,\n",
       "       7636188., 6944000., 3409000., 5005000., 7273000., 3500000.,\n",
       "       4347000., 3592400., 3717000., 8302000., 4018000., 7000000.,\n",
       "       4809700., 6888000., 4279800., 4305000., 5698000., 4081000.,\n",
       "       4720800., 4240600., 5523700., 3703000., 3127600., 3437000.,\n",
       "       3179400., 5532800., 4758600., 3437000., 6048700., 3339000.,\n",
       "       3514000., 4613000., 4130000., 5748400., 7537600., 4095000.,\n",
       "       7656600., 6636000., 3101000., 5999000., 6004600., 4233600.,\n",
       "       5152000., 3675000., 4977000., 3175200., 7342188., 3458000.,\n",
       "       2646000., 3675000., 4431000., 3959200., 2614430., 4223800.,\n",
       "       9051000., 3724000., 4327400., 3360000., 7154000., 5971000.,\n",
       "       3897600., 3437000., 3458000., 7546000., 3234000., 4898600.,\n",
       "       3630200., 7070000., 6585600., 4711000., 5262600., 7007000.,\n",
       "       5306000., 4541600., 4921700., 5831000., 7860188., 6950188.,\n",
       "       5184200., 2828000., 4641700., 3299800., 3325000., 3374000.,\n",
       "       6272000., 5082000., 5740000., 6286000., 4849600., 7273000.,\n",
       "       4538800., 6342000., 7217000., 3591000., 8666000., 3234000.,\n",
       "       6993000., 4866400., 2963800., 5741400., 4173400., 3731000.,\n",
       "       3337600., 3533600., 5208000., 4032000., 5262600., 3535000.,\n",
       "       4576600., 4032000., 6151600., 5601400., 3374000., 3423000.,\n",
       "       7007000., 6272000., 3659600., 2821000., 3486000., 3437000.,\n",
       "       8603000., 3479000., 2723000., 7175000., 3668000., 3549000.,\n",
       "       6272000., 3185000., 3729600., 4720800., 2933000.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Название вектора предсказанных значений  y_predict полученого на основании тестового набора\n",
    "y_predict = prediction\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

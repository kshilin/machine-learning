{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Внимание!!! Важно, что бы файлы с данными и исполняемый файл находились в одной папке, \n",
    "# тогда пути к тестовым и тренировочным наборам будут содержать только имена файлов.\n",
    "# \n",
    "# В пути к тренировочным и тестовым данным запрежается использовать абсалютную адресацию, \n",
    "# то есть адресацию, в которой присутствуют имена папок. Путь должен содержать только имя файла.\n",
    "#\n",
    "# Напоминание: под моделью машинного обучения понимаются все действия с исходными данными, \n",
    "# которые необходимо произвести, что бы сопоставить признаки целевому значению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 1 (библиотеки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный блок в области 1 НЕ выполняется преподавателем\n",
    "# \n",
    "# данный блок предназначен только для подключения необходимых библиотек\n",
    "# запрещается подключать библиотеки в других блоках\n",
    "# запрещается скрывать предупреждения системы\n",
    "# установка дополнительных библиотек размещается прямо здесь (обязательно закоментированы)\n",
    "# pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer\n",
    "from IPython.display import display\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score  \n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 2 (поиск  модели .... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный блок(и) НЕ выполняются преподавателем в области 2\n",
    "# блок(и) предназначены для поиска лучшей модели \n",
    "# должен быть понятен и очевиден отбор параметров модели\n",
    "# оставляйте свои комментарии и разъяснения\n",
    "# \n",
    "# Запрещается размещать данные блоки за пределами обасти 2\n",
    "# Все блоки данной области должны быть выполнены\n",
    "#\n",
    "# ЗАПРЕЩАЕТСЯ ИСПОЛЬЗОВАТЬ ТЕСТОВЫЙ НАБОР\n",
    "#\n",
    "# Путь к тренировочному набору\n",
    "# \n",
    "\n",
    "path_train = 'train.csv' # содержит только имя файла, без имен папок !!!\n",
    "wine = pd.read_csv(path_train)\n",
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(wine.describe())\n",
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine[wine.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine['quality'] = [0 if i<7 else 1 for i in wine['quality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop(columns = 'quality')\n",
    "Y = wine.quality\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3,stratify = Y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = np.arange(1, 30)\n",
    "weights = ['uniform', 'distance']\n",
    "scaling = [ MinMaxScaler(), StandardScaler(),RobustScaler(), Normalizer()]\n",
    "preprocessing = [LogisticRegression(), KNeighborsClassifier(),GaussianNB()]\n",
    "p = np.arange(1, 6)\n",
    "C = np.logspace(-4, 4, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', MinMaxScaler()),\n",
    "                   ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "param_grid = [{'preprocessing' : scaling,\n",
    "               'classifier' : [KNeighborsClassifier()],\n",
    "               'classifier__n_neighbors' : n_neighbors,\n",
    "               'classifier__weights' : weights,\n",
    "               'classifier__p' : p},\n",
    "               {'preprocessing' : scaling,\n",
    "                'classifier' : [GaussianNB()]},\n",
    "               {'preprocessing': scaling,\n",
    "                    'classifier': [LogisticRegression()],\n",
    "                    'classifier__penalty': ['l2'],\n",
    "                    'classifier__solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "                   'classifier__C' : C},\n",
    "               {'preprocessing': scaling,\n",
    "                'classifier': [LogisticRegression()],\n",
    "                    'classifier__penalty': ['l1'],\n",
    "                    'classifier__solver': ['liblinear', 'saga'],\n",
    "                    'classifier__C' : C},\n",
    "               {'preprocessing': scaling,\n",
    "                'classifier': [LogisticRegression()],\n",
    "                    'classifier__penalty': ['none'],\n",
    "                    'classifier__solver': ['lbfgs','newton-cg', 'newton-cholesky', 'saga'],\n",
    "                    'classifier__C' : C},\n",
    "               {'preprocessing': scaling,\n",
    "                'classifier': [LogisticRegression()],\n",
    "                    'classifier__penalty' : ['elasticnet'],\n",
    "                    'classifier__solver' : ['saga'],\n",
    "                    'classifier__C' : C}]\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_pred_3 = grid_search.predict(X_test)\n",
    "\n",
    "print(\"best params: \\n{}\\n\".format(grid_search.best_params_))\n",
    "print(\"accuarcy scor train: {:.6f}\\n\".format(grid_search.score(X_train, y_train))) \n",
    "print(\"accuarcy scor test: {:.6f}\\n\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('recall:    ', roc_auc_score(y_test,  y_pred_3))\n",
    "print('precision: ', precision_score(y_test,  y_pred_3))\n",
    "print('f1:        ', f1_score(y_test,  y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(class_weight='balanced')\n",
    "pipe_2 = Pipeline([('preprocessing', StandardScaler()),\n",
    "                    ('classifier', logistic_regression)])\n",
    "param_grid_2 =[{'preprocessing': scaling,\n",
    "                    'classifier__penalty': ['l2'],\n",
    "                    'classifier__solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "                   'classifier__C' : C},\n",
    "               {'preprocessing': scaling,\n",
    "                    'classifier__penalty': ['l1'],\n",
    "                    'classifier__solver': ['liblinear', 'saga'],\n",
    "                    'classifier__C' : C},\n",
    "               {'preprocessing': scaling,\n",
    "                    'classifier__penalty': ['none'],\n",
    "                    'classifier__solver': ['lbfgs','newton-cg', 'newton-cholesky', 'saga'],\n",
    "                    'classifier__C' : C},\n",
    "               {'preprocessing': scaling,\n",
    "                    'classifier__penalty' : ['elasticnet'],\n",
    "                    'classifier__solver' : ['saga'],\n",
    "                    'classifier__C' : C}]\n",
    "grid_search_2 = GridSearchCV(pipe_2, param_grid_2, return_train_score = True)\n",
    "grid_search_2.fit(X_train, y_train)\n",
    "y_pred_4 = grid_search_2.predict(X_test)\n",
    "predicted_probabilities = grid_search_2.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.5\n",
    "predicted_labels = (predicted_probabilities >= threshold).astype(int)\n",
    "precision = precision_score(y_test, predicted_labels)\n",
    "print(\"Метрика Precision с порогом\", threshold, \":\", precision)\n",
    "print(\"Метрика recall\", \":\", recall_score(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = pd.DataFrame(grid_search_2.cv_results_).sort_values([\"rank_test_score\",'std_test_score']).T\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_2.fit(X_train,y_train)\n",
    "y_pred_2 = pipe_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
